\paragraph{NAME\label{NAME}\index{NAME}}


combineCtrl - controls a Combine crawling job

\paragraph{SYNOPSIS\label{SYNOPSIS}\index{SYNOPSIS}}


combineCtrl  $<$action$>$ --jobname $<$name$>$



where action can be one of start, kill, load, recyclelinks, reharvest, stat,
howmany, records, hosts, initMemoryTables, open, stop, pause, continue

\paragraph{OPTIONS AND ARGUMENTS\label{OPTIONS_AND_ARGUMENTS}\index{OPTIONS AND ARGUMENTS}}


jobname is used to find the appropriate configuration (mandatory)

\subparagraph*{Actions starting/killing crawlers\label{Actions_starting_killing_crawlers}\index{Actions starting/killing crawlers}}
\begin{description}

\item[{start}] \mbox{}

takes an optional switch \texttt{--harvesters n} where \texttt{n} is the number of
crawler processes to start


\item[{kill}] \mbox{}

kills all active crawlers (and their associated combineRun monitors) for jobnam

\end{description}
\subparagraph*{Actions loading or recycling URLs for crawling\label{Actions_loading_or_recycling_URLs_for_crawling}\index{Actions loading or recycling URLs for crawling}}
\begin{description}

\item[{load}] \mbox{}

Read a list of URLs from STDIN (one per line) and schedules them for crawling


\item[{recyclelinks}] \mbox{}

Schedule all newly found (since last invocation of recyclelinks) 
links in crawled pages for crawling


\item[{reharvest}] \mbox{}

Schedules all pages in the database for crawling again (in order to check if
they have changed)

\end{description}
\subparagraph*{Actions for controlling scheduling of URLs\label{Actions_for_controlling_scheduling_of_URLs}\index{Actions for controlling scheduling of URLs}}
\begin{description}

\item[{open}] \mbox{}

opens database for URL scheduling (maybe after a stop)


\item[{stop}] \mbox{}

stops URL scheduling


\item[{pause}] \mbox{}

pauses URL scheduling


\item[{continue}] \mbox{}

continues  URL scheduling after a pause

\end{description}
\subparagraph*{Misc actions\label{Misc_actions}\index{Misc actions}}
\begin{description}

\item[{stat}] \mbox{}

prints out rudimentary status of the ready queue (ie eligible now) of URLs to be crawled


\item[{howmany}] \mbox{}

prints out rudimentary status of all URLs to be crawled


\item[{records}] \mbox{}

prints out the number of ercords in the SQL database


\item[{hosts}] \mbox{}

prints out rudimentary status of all hosts that have URLs to be crawled


\item[{initMemoryTables}] \mbox{}

initializes the administrative MySQL tables that are kept in memory

\end{description}
\paragraph{DESCRIPTION\label{DESCRIPTION}\index{DESCRIPTION}}


Implements various control functionality to administer a crawling job,
like starting and stoping crawlers, injecting URLs into the crawl queue,
scheduling newly found links for crawling, controlling scheduling, etc.



This is the preferred way of controling a crawl job.

\paragraph{EXAMPLES\label{EXAMPLES}\index{EXAMPLES}}
\begin{description}

\item[{\texttt{echo 'http://www.yourdomain.com/' $|$ combineCtrl load --jobname aatest}}] \mbox{}

Seed the crawling job \texttt{aatest} with a URL


\item[{\texttt{combineCtrl start --jobname aatest --harvesters 3}}] \mbox{}

Start 3 crawling processes for job \texttt{aatest}


\item[{\texttt{combineCtrl recyclelinks --jobname aatest}}] \mbox{}

Schedule all new links crawling


\item[{\texttt{combineCtrl stat --jobname aatest}}] \mbox{}

See how many URLs that are eligible for crawling right now.

\end{description}
\paragraph{SEE ALSO\label{SEE_ALSO}\index{SEE ALSO}}


combine



Combine configuration documentation in \emph{/usr/share/doc/combine/}.

\paragraph{AUTHOR\label{AUTHOR}\index{AUTHOR}}


Anders Ardö, $<$anders.ardo@it.lth.se$>$

\paragraph{COPYRIGHT AND LICENSE\label{COPYRIGHT_AND_LICENSE}\index{COPYRIGHT AND LICENSE}}


Copyright (C) 2005 Anders Ardö



This library is free software; you can redistribute it and/or modify
it under the same terms as Perl itself, either Perl version 5.8.4 or,
at your option, any later version of Perl 5 you may have available.



See the file LICENCE included in the distribution at
 \textsf{http://combine.it.lth.se/}

