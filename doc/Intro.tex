\section{Introduction}

%%%%%\begin{executivesummary}
%The executive summary should provide more background and context over
% and above the abstract, and also
% possibly include a road-map to the document.
%Section \ref{foo}: ...

The Combine system is an open, free, and highly configurable system for focused crawling of Internet resources.

\begin{figure}[htb]
\begin{center}
 \includegraphics[height=0.3\textheight, width=0.8\textwidth]{focusedrobot.eps}
\end{center}
\caption{Overview of Combine focused crawler.}
\label{overview}
\end{figure}

Main features include
\begin{itemize}
\item part of the \htmladdnormallinkfoot{SearchEngine-in-a-Box}{http://combine.it.lth.se/SearchEngineBox/} system
\item extensive configuration possibilities
\item integrated topic filter (automated topic classifier) for focused crawling mode
\item possibility to use any topic filter (if provided as a \htmladdnormallinkfoot{Perl Plug-In module}{http://combine.it.lth.se/PlugIns/}) in focused crawling mode
\item crawl limitations based on regular expression on URLs both include and exclude (URL focus filter)
\item character set detection/normalization
\item language detection
\item HTML cleaning
\item metadata extraction
\item structured records for each crawled page
\item supports many document types (text, HTML, PDF, PostScript, MsWord, PowerPoint, Excel, RTF, TeX, images)
\item SQL database for data storage and administration
\end{itemize}

Naturally it obeys the \htmladdnormallinkfoot{Robots
  Exclusion Protocol}{http://www.robotstxt.org/wc/exclusion.html}
and behaves nice to Web-servers. Besides focused crawls (generating
topic specific databases) Combine supports configurable rules on
what's crawled based on regular expressions on URLs (URL focus filter).
The crawler is designed to run continuously in order to keep
the topic-specific database as up to date as possible.

The operation of Combine (overview in figure \ref{overview}) as a focused crawler is based on a combination of a
general Web crawler and an automated subject classifier. The topic
focus is provided by a focus filter using a topic
definition implemented as a thesaurus, where each term is connected to a
topic class.

Crawled data are stored as a
structured records in a local relational database.

%%%%%%%%%%%%%%%%
Section \ref{distr}
 outlines how to download, install and test the Combine system and includes use scenarios.

Section \ref{configuration} discuss configuration structure and highlights a few important configuration variables.

Section \ref{operation} describes policies and methods used by the crawler.

%%%%\end{executivesummary}

The system has a number of \hyperref{components}{components (see
section }{)}{comp}, the main user visible ones being {\tt combineCtrl}
which is used to start and stop crawling, and view crawler status and
{\tt combineExport} that extracts crawled data from the internal
database and exports it as XML records.

Further details (lots and lots of them) can be found in \hyperref{'Gory details'}{part }{ 'Gory details'}{gory} and in \hyperref{the Appendix}{Appendix }{}{appendix}.
