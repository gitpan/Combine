<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">

<!--Converted with LaTeX2HTML 2002-2-1 (1.70)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>APPENDIX</TITLE>
<META NAME="description" CONTENT="APPENDIX">
<META NAME="keywords" CONTENT="DocMain">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="LaTeX2HTML v2002-2-1">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="DocMain.css">

<LINK REL="previous" HREF="node15.html">
<LINK REL="up" HREF="node15.html">
<LINK REL="next" HREF="node17.html">
</HEAD>

<BODY >

<DIV CLASS="navigation"><!--Navigation Panel-->
<A NAME="tex2html736"
  HREF="node17.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next" SRC="next.png"></A> 
<A NAME="tex2html732"
  HREF="node15.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up" SRC="up.png"></A> 
<A NAME="tex2html728"
  HREF="node15.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous" SRC="prev.png"></A> 
<A NAME="tex2html734"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents" SRC="contents.png"></A>  
<BR>
<B> Next:</B> <A NAME="tex2html737"
  HREF="node17.html">About this document ...</A>
<B> Up:</B> <A NAME="tex2html733"
  HREF="node15.html">.</A>
<B> Previous:</B> <A NAME="tex2html729"
  HREF="node15.html">.</A>
 &nbsp; <B>  <A NAME="tex2html735"
  HREF="node1.html">Contents</A></B> 
<BR>
<BR></DIV>
<!--End of Navigation Panel-->
<!--Table of Child-Links-->
<A NAME="CHILD_LINKS"><STRONG>Subsections</STRONG></A>

<UL CLASS="ChildLinks">
<LI><A NAME="tex2html738"
  HREF="node16.html#SECTION05011000000000000000">Simple installation test</A>
<UL>
<LI><A NAME="tex2html739"
  HREF="node16.html#SECTION05011100000000000000">InstallationTest.pl</A>
</UL>
<BR>
<LI><A NAME="tex2html740"
  HREF="node16.html#SECTION05012000000000000000">Example topic filter plug in</A>
<UL>
<LI><A NAME="tex2html741"
  HREF="node16.html#SECTION05012100000000000000">classifyPlugInTemplate.pm</A>
</UL>
<BR>
<LI><A NAME="tex2html742"
  HREF="node16.html#SECTION05013000000000000000">Default configuration files</A>
<UL>
<LI><A NAME="tex2html743"
  HREF="node16.html#SECTION05013100000000000000">Global</A>
<LI><A NAME="tex2html744"
  HREF="node16.html#SECTION05013200000000000000">Job specific</A>
</UL>
<BR>
<LI><A NAME="tex2html745"
  HREF="node16.html#SECTION05014000000000000000">SQL database</A>
<UL>
<LI><A NAME="tex2html746"
  HREF="node16.html#SECTION05014100000000000000">Create database</A>
<LI><A NAME="tex2html747"
  HREF="node16.html#SECTION05014200000000000000">Creating MySQL tables</A>
<LI><A NAME="tex2html748"
  HREF="node16.html#SECTION05014300000000000000">Data tables</A>
<LI><A NAME="tex2html749"
  HREF="node16.html#SECTION05014400000000000000">Administrative tables</A>
<LI><A NAME="tex2html750"
  HREF="node16.html#SECTION05014500000000000000">Create user dbuser with required priviligies</A>
</UL>
<BR>
<LI><A NAME="tex2html751"
  HREF="node16.html#SECTION05015000000000000000">Manual pages</A>
<UL>
<LI><A NAME="tex2html752"
  HREF="node16.html#SECTION05015100000000000000">combineCtrl</A>
<UL>
<LI><A NAME="tex2html753"
  HREF="node16.html#SECTION05015110000000000000">NAME</A>
<LI><A NAME="tex2html754"
  HREF="node16.html#SECTION05015120000000000000">SYNOPSIS</A>
<LI><A NAME="tex2html755"
  HREF="node16.html#SECTION05015130000000000000">OPTIONS AND ARGUMENTS</A>
<UL>
<LI><A NAME="tex2html756"
  HREF="node16.html#SECTION05015131000000000000">Actions starting/killing crawlers</A>
<LI><A NAME="tex2html757"
  HREF="node16.html#SECTION05015132000000000000">Actions loading or recycling URLs for crawling</A>
<LI><A NAME="tex2html758"
  HREF="node16.html#SECTION05015133000000000000">Actions for controlling scheduling of URLs</A>
<LI><A NAME="tex2html759"
  HREF="node16.html#SECTION05015134000000000000">Misc actions</A>
</UL>
<LI><A NAME="tex2html760"
  HREF="node16.html#SECTION05015140000000000000">DESCRIPTION</A>
<LI><A NAME="tex2html761"
  HREF="node16.html#SECTION05015150000000000000">EXAMPLES</A>
<LI><A NAME="tex2html762"
  HREF="node16.html#SECTION05015160000000000000">SEE ALSO</A>
<LI><A NAME="tex2html763"
  HREF="node16.html#SECTION05015170000000000000">AUTHOR</A>
<LI><A NAME="tex2html764"
  HREF="node16.html#SECTION05015180000000000000">COPYRIGHT AND LICENSE</A>
</UL>
<LI><A NAME="tex2html765"
  HREF="node16.html#SECTION05015200000000000000">combine</A>
<UL>
<LI><A NAME="tex2html766"
  HREF="node16.html#SECTION05015210000000000000">NAME</A>
<LI><A NAME="tex2html767"
  HREF="node16.html#SECTION05015220000000000000">SYNOPSIS</A>
<LI><A NAME="tex2html768"
  HREF="node16.html#SECTION05015230000000000000">OPTIONS AND ARGUMENTS</A>
<LI><A NAME="tex2html769"
  HREF="node16.html#SECTION05015240000000000000">DESCRIPTION</A>
<LI><A NAME="tex2html770"
  HREF="node16.html#SECTION05015250000000000000">SEE ALSO</A>
<LI><A NAME="tex2html771"
  HREF="node16.html#SECTION05015260000000000000">AUTHOR</A>
<LI><A NAME="tex2html772"
  HREF="node16.html#SECTION05015270000000000000">COPYRIGHT AND LICENSE</A>
</UL>
<LI><A NAME="tex2html773"
  HREF="node16.html#SECTION05015300000000000000">combineExport</A>
<UL>
<LI><A NAME="tex2html774"
  HREF="node16.html#SECTION05015310000000000000">NAME</A>
<LI><A NAME="tex2html775"
  HREF="node16.html#SECTION05015320000000000000">SYNOPSIS</A>
<LI><A NAME="tex2html776"
  HREF="node16.html#SECTION05015330000000000000">OPTIONS AND ARGUMENTS</A>
<LI><A NAME="tex2html777"
  HREF="node16.html#SECTION05015340000000000000">DESCRIPTION</A>
<LI><A NAME="tex2html778"
  HREF="node16.html#SECTION05015350000000000000">EXAMPLES</A>
<LI><A NAME="tex2html779"
  HREF="node16.html#SECTION05015360000000000000">SEE ALSO</A>
<LI><A NAME="tex2html780"
  HREF="node16.html#SECTION05015370000000000000">AUTHOR</A>
<LI><A NAME="tex2html781"
  HREF="node16.html#SECTION05015380000000000000">COPYRIGHT AND LICENSE</A>
</UL>
<LI><A NAME="tex2html782"
  HREF="node16.html#SECTION05015400000000000000">combineRank</A>
<UL>
<LI><A NAME="tex2html783"
  HREF="node16.html#SECTION05015410000000000000">NAME</A>
<LI><A NAME="tex2html784"
  HREF="node16.html#SECTION05015420000000000000">SYNOPSIS</A>
<LI><A NAME="tex2html785"
  HREF="node16.html#SECTION05015430000000000000">OPTIONS AND ARGUMENTS</A>
<UL>
<LI><A NAME="tex2html786"
  HREF="node16.html#SECTION05015431000000000000">Actions calculating variants of PageRank</A>
<LI><A NAME="tex2html787"
  HREF="node16.html#SECTION05015432000000000000">Actions exporting link data</A>
</UL>
<LI><A NAME="tex2html788"
  HREF="node16.html#SECTION05015440000000000000">DESCRIPTION</A>
<LI><A NAME="tex2html789"
  HREF="node16.html#SECTION05015450000000000000">EXAMPLES</A>
<LI><A NAME="tex2html790"
  HREF="node16.html#SECTION05015460000000000000">SEE ALSO</A>
<LI><A NAME="tex2html791"
  HREF="node16.html#SECTION05015470000000000000">AUTHOR</A>
<LI><A NAME="tex2html792"
  HREF="node16.html#SECTION05015480000000000000">COPYRIGHT AND LICENSE</A>
</UL>
<LI><A NAME="tex2html793"
  HREF="node16.html#SECTION05015500000000000000">combineRun</A>
<UL>
<LI><A NAME="tex2html794"
  HREF="node16.html#SECTION05015510000000000000">NAME</A>
<LI><A NAME="tex2html795"
  HREF="node16.html#SECTION05015520000000000000">SYNOPSIS</A>
<LI><A NAME="tex2html796"
  HREF="node16.html#SECTION05015530000000000000">DESCRIPTION</A>
<LI><A NAME="tex2html797"
  HREF="node16.html#SECTION05015540000000000000">SEE ALSO</A>
<LI><A NAME="tex2html798"
  HREF="node16.html#SECTION05015550000000000000">AUTHOR</A>
<LI><A NAME="tex2html799"
  HREF="node16.html#SECTION05015560000000000000">COPYRIGHT AND LICENSE</A>
</UL>
<LI><A NAME="tex2html800"
  HREF="node16.html#SECTION05015600000000000000">combineUtil</A>
<UL>
<LI><A NAME="tex2html801"
  HREF="node16.html#SECTION05015610000000000000">NAME</A>
<LI><A NAME="tex2html802"
  HREF="node16.html#SECTION05015620000000000000">SYNOPSIS</A>
<LI><A NAME="tex2html803"
  HREF="node16.html#SECTION05015630000000000000">OPTIONS AND ARGUMENTS</A>
<UL>
<LI><A NAME="tex2html804"
  HREF="node16.html#SECTION05015631000000000000">Actions listing statistics</A>
<LI><A NAME="tex2html805"
  HREF="node16.html#SECTION05015632000000000000">Actions for sanity controlls</A>
<LI><A NAME="tex2html806"
  HREF="node16.html#SECTION05015633000000000000">Action all</A>
<LI><A NAME="tex2html807"
  HREF="node16.html#SECTION05015634000000000000">Actions for deleting records</A>
<LI><A NAME="tex2html808"
  HREF="node16.html#SECTION05015635000000000000">Actions for handling server aliases</A>
</UL>
<LI><A NAME="tex2html809"
  HREF="node16.html#SECTION05015640000000000000">DESCRIPTION</A>
<LI><A NAME="tex2html810"
  HREF="node16.html#SECTION05015650000000000000">EXAMPLES</A>
<LI><A NAME="tex2html811"
  HREF="node16.html#SECTION05015660000000000000">SEE ALSO</A>
<LI><A NAME="tex2html812"
  HREF="node16.html#SECTION05015670000000000000">AUTHOR</A>
<LI><A NAME="tex2html813"
  HREF="node16.html#SECTION05015680000000000000">COPYRIGHT AND LICENSE</A>
</UL>
<LI><A NAME="tex2html814"
  HREF="node16.html#SECTION05015700000000000000">Combine::FromHTML</A>
<UL>
<LI><A NAME="tex2html815"
  HREF="node16.html#SECTION05015710000000000000">NAME</A>
<LI><A NAME="tex2html816"
  HREF="node16.html#SECTION05015720000000000000">AUTHOR</A>
</UL>
<LI><A NAME="tex2html817"
  HREF="node16.html#SECTION05015800000000000000">Combine::FromTeX</A>
<UL>
<LI><A NAME="tex2html818"
  HREF="node16.html#SECTION05015810000000000000">NAME</A>
<LI><A NAME="tex2html819"
  HREF="node16.html#SECTION05015820000000000000">AUTHOR</A>
</UL>
<LI><A NAME="tex2html820"
  HREF="node16.html#SECTION05015900000000000000">Combine::HTMLExtractor</A>
<UL>
<LI><A NAME="tex2html821"
  HREF="node16.html#SECTION05015910000000000000">NAME</A>
<LI><A NAME="tex2html822"
  HREF="node16.html#SECTION05015920000000000000">DESCRIPTION</A>
<LI><A NAME="tex2html823"
  HREF="node16.html#SECTION05015930000000000000">AUTHOR
Anders Ardo</A>
<LI><A NAME="tex2html824"
  HREF="node16.html#SECTION05015940000000000000">LICENSE</A>
</UL>
<LI><A NAME="tex2html825"
  HREF="node16.html#SECTION050151000000000000000">Combine::LoadTermList</A>
<UL>
<LI><A NAME="tex2html826"
  HREF="node16.html#SECTION050151010000000000000">NAME</A>
<LI><A NAME="tex2html827"
  HREF="node16.html#SECTION050151020000000000000">DESCRIPTION</A>
<LI><A NAME="tex2html828"
  HREF="node16.html#SECTION050151030000000000000">AUTHOR</A>
<LI><A NAME="tex2html829"
  HREF="node16.html#SECTION050151040000000000000">COPYRIGHT AND LICENSE</A>
</UL>
<LI><A NAME="tex2html830"
  HREF="node16.html#SECTION050151100000000000000">Combine::Matcher</A>
<UL>
<LI><A NAME="tex2html831"
  HREF="node16.html#SECTION050151110000000000000">NAME</A>
<LI><A NAME="tex2html832"
  HREF="node16.html#SECTION050151120000000000000">DESCRIPTION</A>
<LI><A NAME="tex2html833"
  HREF="node16.html#SECTION050151130000000000000">AUTHOR</A>
<LI><A NAME="tex2html834"
  HREF="node16.html#SECTION050151140000000000000">COPYRIGHT AND LICENSE</A>
</UL>
<LI><A NAME="tex2html835"
  HREF="node16.html#SECTION050151200000000000000">Combine::PosMatcher</A>
<UL>
<LI><A NAME="tex2html836"
  HREF="node16.html#SECTION050151210000000000000">NAME</A>
<LI><A NAME="tex2html837"
  HREF="node16.html#SECTION050151220000000000000">DESCRIPTION</A>
<LI><A NAME="tex2html838"
  HREF="node16.html#SECTION050151230000000000000">AUTHOR</A>
<LI><A NAME="tex2html839"
  HREF="node16.html#SECTION050151240000000000000">COPYRIGHT AND LICENSE</A>
</UL>
<LI><A NAME="tex2html840"
  HREF="node16.html#SECTION050151300000000000000">Combine::RobotRules</A>
<UL>
<LI><A NAME="tex2html841"
  HREF="node16.html#SECTION050151310000000000000">NAME</A>
<LI><A NAME="tex2html842"
  HREF="node16.html#SECTION050151320000000000000">AUTHOR</A>
</UL>
<LI><A NAME="tex2html843"
  HREF="node16.html#SECTION050151400000000000000">Combine::SD_SQL</A>
<UL>
<LI><A NAME="tex2html844"
  HREF="node16.html#SECTION050151410000000000000">NAME</A>
<LI><A NAME="tex2html845"
  HREF="node16.html#SECTION050151420000000000000">DESCRIPTION</A>
<LI><A NAME="tex2html846"
  HREF="node16.html#SECTION050151430000000000000">AUTHOR</A>
<LI><A NAME="tex2html847"
  HREF="node16.html#SECTION050151440000000000000">COPYRIGHT AND LICENSE</A>
</UL>
<LI><A NAME="tex2html848"
  HREF="node16.html#SECTION050151500000000000000">Combine::XWI</A>
<UL>
<LI><A NAME="tex2html849"
  HREF="node16.html#SECTION050151510000000000000">NAME</A>
<LI><A NAME="tex2html850"
  HREF="node16.html#SECTION050151520000000000000">SYNOPSIS</A>
<LI><A NAME="tex2html851"
  HREF="node16.html#SECTION050151530000000000000">DESCRIPTION</A>
<LI><A NAME="tex2html852"
  HREF="node16.html#SECTION050151540000000000000">METHODS</A>
<UL>
<LI><A NAME="tex2html853"
  HREF="node16.html#SECTION050151541000000000000">new()</A>
<LI><A NAME="tex2html854"
  HREF="node16.html#SECTION050151542000000000000">XXX($val)</A>
<LI><A NAME="tex2html855"
  HREF="node16.html#SECTION050151543000000000000">*_reset()</A>
<LI><A NAME="tex2html856"
  HREF="node16.html#SECTION050151544000000000000">*_rewind()</A>
<LI><A NAME="tex2html857"
  HREF="node16.html#SECTION050151545000000000000">*_add</A>
<LI><A NAME="tex2html858"
  HREF="node16.html#SECTION050151546000000000000">*_get</A>
<LI><A NAME="tex2html859"
  HREF="node16.html#SECTION050151547000000000000">meta_reset() / meta_rewind() / meta_add() / meta_get()</A>
<LI><A NAME="tex2html860"
  HREF="node16.html#SECTION050151548000000000000">xmeta_reset() / xmeta_rewind() / xmeta_add() / xmeta_get()</A>
<LI><A NAME="tex2html861"
  HREF="node16.html#SECTION050151549000000000000">url_remove() / url_reset() / url_rewind() / url_add() / url_get()</A>
<LI><A NAME="tex2html862"
  HREF="node16.html#SECTION0501515410000000000000">heading_reset() / heading_rewind() / heading_add() / heading_get()</A>
<LI><A NAME="tex2html863"
  HREF="node16.html#SECTION0501515411000000000000">link_reset() / link_rewind() / link_add() / link_get()</A>
<LI><A NAME="tex2html864"
  HREF="node16.html#SECTION0501515412000000000000">robot_reset() / robot_rewind() / robot_add() / robot_get()</A>
<LI><A NAME="tex2html865"
  HREF="node16.html#SECTION0501515413000000000000">topic_reset() / topic_rewind() / topic_add() / topic_get()</A>
</UL>
<LI><A NAME="tex2html866"
  HREF="node16.html#SECTION050151550000000000000">SEE ALSO</A>
<LI><A NAME="tex2html867"
  HREF="node16.html#SECTION050151560000000000000">AUTHOR</A>
<LI><A NAME="tex2html868"
  HREF="node16.html#SECTION050151570000000000000">COPYRIGHT AND LICENSE</A>
</UL>
<LI><A NAME="tex2html869"
  HREF="node16.html#SECTION050151600000000000000">Combine::selurl</A>
<UL>
<LI><A NAME="tex2html870"
  HREF="node16.html#SECTION050151610000000000000">NAME</A>
<LI><A NAME="tex2html871"
  HREF="node16.html#SECTION050151620000000000000">INTRODUCTION</A>
<LI><A NAME="tex2html872"
  HREF="node16.html#SECTION050151630000000000000">BUGS</A>
</UL></UL></UL>
<!--End of Table of Child-Links-->
<HR>

<H1><A NAME="SECTION05010000000000000000"></A>
<A NAME="appendix"></A>
<BR>
APPENDIX
</H1>

<H2><A NAME="SECTION05011000000000000000"></A>
<A NAME="InstTest"></A>
<BR>
Simple installation test
</H2>

<P>
The following simple script is available in the <TT>doc/InstallationTest.pl</TT> file. It must be run as 'root' 
and tests that basic functions of the Combine installation works.

<P>
Basicly it creates and initializes a new jobname, crawls one
specific test page and exports it as XML. This XML is then
compared to a correct XML-record for that page. 

<P>

<H3><A NAME="SECTION05011100000000000000">
InstallationTest.pl</A>
</H3>
<PRE>
use strict;
if ( $&gt; != 0 ) {
    die("You have to run this test as root");
}

my $orec='';
while (&lt;DATA&gt;) { chop; $orec .= $_; }

$orec =~ s|&lt;checkedDate&gt;.*&lt;/checkedDate&gt;||;
$orec =~ tr/\n\t //d;

my $olen=length($orec);
my $onodes=0;
while ( $orec =~ m/&lt;/g ) { $onodes++; }
print "ORIG Nodes=$onodes; Len=$olen\n";

our $jobname;
require './t/defs.pm';

system("combineINIT --jobname $jobname --topic /etc/combine/Topic_carnivor.txt &gt;&amp; /dev/null");

system("combine --jobname $jobname --harvest http://combine.it.lth.se/CombineTests/InstallationTest.html");
open(REC,"combineExport --jobname $jobname |");
my $rec='';
while (&lt;REC&gt;) { chop; $rec .= $_; }
close(REC);
$rec =~ s|&lt;checkedDate&gt;.*&lt;/checkedDate&gt;||;
$rec =~ tr/\n\t //d;

my $len=length($rec);
my $nodes=0;
while ( $rec =~ m/&lt;/g ) { $nodes++; }
print "NEW Nodes=$nodes; Len=$len\n";

my $OK=0;

if ($onodes == $nodes) { print "Number of XML nodes match\n"; }
else { print "Number of XML nodes does NOT match\n"; $OK=1; }
if ($olen == $len) {
  print "Size of XML match\n";
} else {
  $orec =~  s|&lt;originalDocument.*&lt;/originalDocument&gt;||s;
  $rec =~  s|&lt;originalDocument.*&lt;/originalDocument&gt;||s;
  if (length($orec) == length($rec)) { print "Size of XML match (after removal of 'originalDocument')\n";}
  else { print "Size of XML does NOT match\n"; $OK=1; }
}

if (($OK == 0) &amp;&amp; ($orec eq $rec)) { print "All tests OK\n"; }
else { print "There might be some problem with your Combine Installation\n"; }

__END__
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;documentCollection version="1.1" xmlns="http://alvis.info/enriched/"&gt;
&lt;documentRecord id="FC75599D54537931B502035C8D8E652C"&gt;
&lt;acquisition&gt;
&lt;acquisitionData&gt;
&lt;modifiedDate&gt;2006-12-05 13:25:38&lt;/modifiedDate&gt;
&lt;checkedDate&gt;2006-10-03 9:06:42&lt;/checkedDate&gt;
&lt;httpServer&gt;Apache/1.3.29 (Debian GNU/Linux) PHP/4.3.3&lt;/httpServer&gt;
&lt;urls&gt;
    &lt;url&gt;http://combine.it.lth.se/CombineTests/InstallationTest.html&lt;/url&gt;
  &lt;/urls&gt;
&lt;/acquisitionData&gt;
&lt;originalDocument mimeType="text/html" compression="gzip" encoding="base64" charSet="UTF-8"&gt;
H4sIAAAAAAAAA4WQsU7DMBCG9zzF4bmpBV2QcDKQVKJSKR2CEKObXBSrjm3sSyFvT0yCQGJgusG/
//u+E1flU1G9HrfwUD3u4fh8v98VwFLOXzYF52VVzg+b9Q3n2wPLE9FRr+NA2UyDFGnMdyaQ1FqS
sgYIA0FrPRS2PymDgs+hRPRIEozsMWNnHN+tbwKD2hpCQxkrpDfqYr0dAjgtDYUVlN4G9HIFB3RT
qMPAvns6Ipfi26Au09e5I61Gh78aCT+IR947qDvpA1I2UJvexg6+CJxsM0ad6/8kpkQiXB5XSWUC
BNsj/GGG4LBWrarhSw+0OiOIidZjmzGPeh15WL6ICS7zFUjT/AiuBXeRbwHj870/AeRYaTupAQAA
&lt;/originalDocument&gt;
&lt;canonicalDocument&gt;  
  &lt;section&gt;
    &lt;section title="Installation test for Combine"&gt;
      &lt;section&gt;Installation test for Combine&lt;/section&gt; 
      &lt;section&gt;Contains some Carnivorous plant specific words like &lt;ulink url="rel.html"&gt;Drosera &lt;/ulink&gt;, and Nepenthes.&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/canonicalDocument&gt;
&lt;metaData&gt;
    &lt;meta name="title"&gt;Installation test for Combine&lt;/meta&gt;
    &lt;meta name="dc:format"&gt;text/html&lt;/meta&gt;
    &lt;meta name="dc:format"&gt;text/html; charset=iso-8859-1&lt;/meta&gt;
    &lt;meta name="dc:subject"&gt;Carnivorous plants&lt;/meta&gt;
    &lt;meta name="dc:subject"&gt;Drosera&lt;/meta&gt;
    &lt;meta name="dc:subject"&gt;Nepenthes&lt;/meta&gt;
  &lt;/metaData&gt;
&lt;links&gt;
    &lt;outlinks&gt;
      &lt;link type="a"&gt;
        &lt;anchorText&gt;Drosera&lt;/anchorText&gt;
        &lt;location&gt;http://combine.it.lth.se/CombineTests/rel.html&lt;/location&gt;
      &lt;/link&gt;
    &lt;/outlinks&gt;
  &lt;/links&gt;
&lt;analysis&gt;
&lt;property name="topLevelDomain"&gt;se&lt;/property&gt;
&lt;property name="univ"&gt;1&lt;/property&gt;
&lt;property name="language"&gt;en&lt;/property&gt;
&lt;topic absoluteScore="1000" relativeScore="110526"&gt;
    &lt;class&gt;ALL&lt;/class&gt;
  &lt;/topic&gt;
&lt;topic absoluteScore="375" relativeScore="41447"&gt;
    &lt;class&gt;CP.Drosera&lt;/class&gt;
    &lt;terms&gt;drosera&lt;/terms&gt;
  &lt;/topic&gt;
&lt;topic absoluteScore="375" relativeScore="41447"&gt;
    &lt;class&gt;CP.Nepenthes&lt;/class&gt;
    &lt;terms&gt;nepenthe&lt;/terms&gt;
  &lt;/topic&gt;
&lt;topic absoluteScore="250" relativeScore="27632"&gt;
    &lt;class&gt;CP&lt;/class&gt;
    &lt;terms&gt;carnivorous plant&lt;/terms&gt;
    &lt;terms&gt;carnivor&lt;/terms&gt;
  &lt;/topic&gt;
&lt;/analysis&gt;
&lt;/acquisition&gt;
&lt;/documentRecord&gt;

&lt;/documentCollection&gt;
</PRE>

<H2><A NAME="SECTION05012000000000000000"></A>
<A NAME="classifyPlugInTemplate"></A>
<BR>
Example topic filter plug in
</H2>

<P>
This example gives more
details on how to write a topic filter Plug-In. 

<P>

<H3><A NAME="SECTION05012100000000000000">
classifyPlugInTemplate.pm</A>
</H3>
<PRE>
#Template for writing a classify PlugIn for Combine
#See documentation at http://combine.it.lth.se/documentation/

package classifyPlugInTemplate; #Change to your own module name

use Combine::XWI; #Mandatory
use Combine::Config; #Optional if you want to use the Combine configuration system

#API:
#  a subroutine named 'classify' taking a XWI-object as in parameter
#    return values: 0/1
#        0: record fails to meet the classification criteria, ie ignore this record
#        1: record is OK and should be stored in the database, and links followed by the crawler
sub classify { 
  my ($self,$xwi) = @_;

  #utility routines to extract information from the XWI-object
  #URL (can be several):
   # $xwi-&gt;url_rewind;
   # my $url_str="";
   # my $t;
   # while ($t = $xwi-&gt;url_get) { $url_str .= $t . ", "; }

  #Metadata:
   #  $xwi-&gt;meta_rewind;
   #  my ($name,$content);
   #  while (1) {
   #    ($name,$content) = $xwi-&gt;meta_get;
   #    last unless $name;
   #    next if ($name eq 'Rsummary');
   #    next if ($name =~ /^autoclass/);
   #    $meta .= $content . " ";
   #  } 

  #Title:
   #  $title = $xwi-&gt;title;

  #Headings:
   #  $xwi-&gt;heading_rewind;
   #  my $this;
   #  while (1) {
   #    $this = $xwi-&gt;heading_get or last; 
   #    $head .= $this . " "; 
   #  }

  #Text:
   #  $this = $xwi-&gt;text;
   #  if ($this) {
   #    $text = $$this;
   #  }

###############################
#Apply your classification algorithm here
#  assign $result a value (0/1)
###############################

  #utility routines for saving detailed results (optional) in the database. These data may appear
  # in exported XML-records

  #Topic takes 5 parameters
  # $xwi-&gt;topic_add(topic_class_notation, topic_absolute_score, topic_normalized_score, topic_terms, algorithm_id);
  #  topic_class_notation, topic_terms, and algorithm_id are strings
  #    max length topic_class_notation: 50, algorithm_id: 25
  #  topic_absolute_score, and topic_normalized_score are integers
  #  topic_normalized_score and topic_terms are optional and may be replaced with 0, '' respectively

  #Analysis takes 2 parameters
  # $xwi-&gt;robot_add(name,value);
  # both are strings with max length name: 15, value: 20

    # return true (1) if you want to keep the record
    # otherwise return false (0)

  return $result;
}

1;
</PRE>

<H2><A NAME="SECTION05013000000000000000">
Default configuration files</A>
</H2>

<P>
<A NAME="conffiles"></A>
<H3><A NAME="SECTION05013100000000000000">
Global</A>
</H3>

<P>
<PRE>
#@#Default configuration values Combine system

#Direct connection to Zebra indexing - for SearchEngine-in-a-box (default no connection)
#@#ZebraHost = NoDefaultValue
ZebraHost =

#Use a proxy server if this is defined (default no proxy)
#@#httpProxy = NoDefaultValue
httpProxy =

#Enable(1)/disable(0) automatic recycling of new links
AutoRecycleLinks = 1

#User agent handles redirects (1) or treat redirects as new links (0)
UserAgentFollowRedirects = 0

#Number of pages to process before restarting the harvester
HarvesterMaxMissions = 500

#Logging level (0 (least) - 10 (most))
Loglev = 0

#Enable(1)/disable(0) analysis of genre, language
doAnalyse = 1

#How long the summary should be. Use 0 to disable the summarization code
SummaryLength   = 0

#Store(1)/do not store(0) the raw HTML in the database
saveHTML = 1

#Use(1)/do not use(0) Tidy to clean the HTML before parsing it
useTidy = 1

#Use(1)/do not use(0) OAI record status keeping in SQL database
doOAI = 1

#Extract(1)/do not extract(0) links from plain text
extractLinksFromText = 1

#Enable(1)/disable(0) topic classification (focused crawling)
#Generated by combineINIT based on --topic parameter
doCheckRecord = 0

#Which topic classification PlugIn module algorithm to use
#Combine::Check_record and Combine::PosCheck_record included by default
#see classifyPlugInTemplate.pm and documentation to write your own
classifyPlugIn = Combine::Check_record

###Parameters for Std topic classification algorithm
###StdTitleWeight = 10 #
###StdMetaWeight = 4 #
###StdHeadingsWeight = 2 #
###StdCutoffRel = 10 #Class score must be above this % to be counted
###StdCutoffNorm = 0.2 #normalised cutoff for summed normalised score
###StdCutoffTot = 90 #non normalised cutoff for summed total score

###Parameters for Pos topic classification algorithm
###PosCutoffRel = 1 #Class score must be above this % to be counted
###PosCutoffNorm = 0.002 #normalised cutoff for summed normalised score
###PosCutoffTot = 1 #non normalised cutoff for summed total score

HarvestRetries                  = 5
SdqRetries                      = 5

#Maximum length of a URL; longer will be silently discarded
maxUrlLength = 250

#Time in seconds to wait for a server to respond
UAtimeout = 30

#If we have seen this page before use Get-If-Modified (1) or not (0) 
UserAgentGetIfModifiedSince = 1

WaitIntervalExpirationGuaranteed = 315360000
WaitIntervalHarvesterLockNotFound = 2592000
WaitIntervalHarvesterLockNotModified = 2592000
WaitIntervalHarvesterLockRobotRules = 2592000
WaitIntervalHarvesterLockUnavailable = 86400
WaitIntervalRrdLockDefault = 86400
WaitIntervalRrdLockNotFound = 345600
WaitIntervalRrdLockSuccess = 345600

#Time in seconds after succesfull download before allowing a page to be downloaded again (around 11 days)
WaitIntervalHarvesterLockSuccess = 1000000

#Time in seconds to wait before making a new reschedule if a reschedule results in an empty ready que
WaitIntervalSchedulerGetJcf = 20

#Minimum time between accesses to the same host. Must be positive
WaitIntervalHost = 60

#Identifies MySQL database name, user and host
MySQLdatabase   = NoDefaultValue

#Base directory for configuration files; initialized by Config.pm
#@#baseConfigDir = /etc/combine

#Directory for job specific configuration files; taken from 'jobname'
#@#configDir = NoDefaultValue

&lt;binext&gt;
#Extensions of binary files
ps
jpg
jpeg
pdf
tif
tiff
mpg
mpeg
mov
wav
au
hqx
gz
z
tgz
exe
zip
sdd
doc
rtf
shar
mat
raw
wmz
arff
rar
&lt;/binext&gt;

&lt;converters&gt;
#Configure which converters can be used to produce a XWI object
#Format:
#  1 line per entry
#  each entry consists of 3 ';' separated fields
#
#Entries are processed in order and the first match is executed
#  external converters have to be found via PATH and executable to be considered a match
#  the external converter command should take a filename as parameter and convert that file
#   the result should be comming on STDOUT
#
# mime-type   ;   External converter command ; Internal converter

text/html ; ; GuessHTML
#Check this
www/unknown ; ; GuessHTML
text/plain ; ; GuessText
text/x-tex ;  tth -g -w1 -r &lt;  ; TeXHTML
application/x-tex ;  tth -g -w1 -r &lt; ; TeXHTML
text/x-tex ; untex -a -e -giso ; TeXText
application/x-tex ; untex -a -e -giso ; TeXText
text/x-tex ;  ; TeX
application/x-tex ; ; TeX
application/pdf ; pdftohtml -i -noframes -nomerge -stdout ; HTML
application/pdf ; pstotext ; Text
application/postscript ; pstotext ; Text
application/msword ; antiword -t ; Text
application/vnd.ms-excel ; xlhtml -fw ; HTML
application/vnd.ms-powerpoint ; ppthtml ; HTML
application/rtf ; unrtf --nopict --html ; HTML
image/gif ; ; Image
image/jpeg ; ; Image
image/tiff ; ; Image
&lt;/converters&gt;

&lt;url&gt;
  &lt;exclude&gt;
    #Exclude URLs or hostnames that matches these regular expressions
    #Malformed hostnames
    HOST: http:\/\/\.
    HOST: \@
  &lt;/exclude&gt;
&lt;/url&gt;
</PRE>
<H3><A NAME="SECTION05013200000000000000">
Job specific</A>
</H3>

<P>
<PRE>
#Please change
Operator-Email      = "YourEmailAdress@YourDomain"

#Password not used yet. (Please change)
Password    = "XxXxyYzZ"

&lt;converters&gt;
#Configure which converters can be used to produce a XWI object
#Format:
#  1 line per entry
#  each entry consists of 3 ';' separated fields
#
#Entries are processed in order and the first match is executed
#  external converters have to be found via PATH and executable to be considered a match
#  the external converter command should take a filename as parameter and convert that file
#   the result should be comming on STDOUT
#
# mime-type   ;   External converter command ; Internal converter

application/pdf ; MYpdftohtml -i -noframes -nomerge -stdout ; HTML
&lt;/converters&gt;

&lt;url&gt;
#List of servernames that are aliases are in the file ./config_serveralias
#    (automatically updated by other programs)
#use one server per line
#example
#www.100topwetland.com  www.100wetland.com
#  means that www.100wetland.com is replaced by www.100topwetland.com during URL normalization
&lt;serveralias&gt;
&lt;&lt;include config_serveralias&gt;&gt;
&lt;/serveralias&gt;

#use either URL or HOST: (obs ':') to match regular expressions to
# either the full URL or the HOST part of a URL.
&lt;allow&gt;
#Allow crawl of URLs or hostnames that matches these regular expressions
HOST: .*$
&lt;/allow&gt;

&lt;exclude&gt;
#Exclude URLs or hostnames that matches these regular expressions
# default: CGI and maps
URL cgi-bin|htbin|cgi|\?|\.map$|_vti_

# default: binary files
URL \.exe$|\.zip$|\.tar$|\.tgz$|\.gz$|\.hqx$|\.sdd$|\.mat$|\.raw$
URL \.EXE$|\.ZIP$|\.TAR$|\.TGZ$|\.GZ$|\.HQX$|\.SDD$|\.MAT$|\.RAW$

# default: Unparsable documents
URL \.shar$|\.rmx$|\.rmd$|\.mdb$|\.sav$
URL \.SHAR$|\.RMX$|\.RMD$|\.MDB$|\.SAV$

# default: images
URL \.gif$|\.jpg$|\.jpeg$|\.xpm$|\.tif$|\.tiff$|\.mpg$|\.mpeg$|\.mov$|\.wav$|\.au$|\.pcx$|\.xbm$|\.tga$|\.psd$
URL \.GIF$|\.JPG$|\.JPEG$|\.XPM$|\.TIF$|\.TIFF$|\.MPG$|\.MPEG$|\.MOV$|\.WAV$|\.AU$|\.PCX$|\.XBM$|\.TGA$|\.PSD$

# default: other binary formats
URL \.pdb$|\.class$|\.ica$|\.ram$|.wmz$|.arff$|.rar$|\.vo$|\.fig$
URL \.PDB$|\.CLASS$|\.ICA$|\.RAM$|.WMZ$|.ARFF$|.RAR$|\.VO$|\.FIG$

#more excludes in the file config_exclude (automatically updated by other programs)
&lt;&lt;include config_exclude&gt;&gt;
&lt;/exclude&gt;
&lt;sessionids&gt;
#patterns to recognize and remove sessionids in URLs
sessionid
lsessionid
jsessionid
SID
PHPSESSID
SessionID
BV_SessionID
&lt;/sessionids&gt;
#url is just a conatiner for all URL related configuration patterns
&lt;/url&gt;
</PRE>

<H2><A NAME="SECTION05014000000000000000"></A>
<A NAME="sqlstruct"></A>
<BR>
SQL database
</H2>

<H3><A NAME="SECTION05014100000000000000">
Create database</A>
</H3>
<code>DROP DATABASE IF EXISTS $database;</code>
<BR><code>CREATE DATABASE $database DEFAULT CHARACTER SET utf8;</code>
<BR><code>USE $database;</code>
<BR>
<H3><A NAME="SECTION05014200000000000000">
Creating MySQL tables</A>
</H3>
<code>All tables use UTF-8</code>
<BR><code></code>
<BR><code>Summary tables '^'=primary key, '*'=key:</code>
<BR><code>TABLE hdb: recordid^, type, dates, server, title, ip, ...</code>
<BR><code>TABLE links: recordid*, mynetlocid*, urlid*, netlocid*, linktype, anchor  (netlocid for urlid!!)</code>
<BR><code>TABLE meta: recordid*,  name, value</code>
<BR><code>TABLE html: recordid^, html</code>
<BR><code>TABLE analys: recordid*, name, value</code>
<BR><code>TABLE topic: recordid*, notation*, absscore, relscore, terms, algorithm</code>
<BR><code></code>
<BR><code>(TABLE netlocalias: netlocid*, netlocstr^)</code>
<BR><code>(TABLE urlalias: urlid*, urlstr^)</code>
<BR><code>TABLE topichierarchy: node^, father*, notation*, caption, level</code>
<BR><code>TABLE netlocs: netlocid^, netlocstr^, retries</code>
<BR><code>TABLE urls: netlocid*, urlid^, urlstr^, path</code>
<BR><code>TABLE urldb: netlocid*, urlid^, urllock, harvest*, retries, netloclock</code>
<BR><code>TABLE newlinks urlid^, netlocid</code>
<BR><code>TABLE recordurl: recordid*, urlid^, lastchecked, md5*, fingerprint*^</code>
<BR><code>TABLE admin: status, queid, schedulealgorithm</code>
<BR><code>TABLE log: pid, id, date, message</code>
<BR><code>TABLE que: queid^, urlid, netlocid</code>
<BR><code>TABLE robotrules: netlocid*, rule, expire</code>
<BR><code>TABLE oai: recordid, md5^, date*, status</code>
<BR><code>TABLE exports: host, port, last</code>
<BR>
<H3><A NAME="SECTION05014300000000000000">
Data tables</A>
</H3>
<PRE>
CREATE TABLE hdb (
  recordid int(11) NOT NULL default '0',
  type varchar(50) default NULL,
  title text,
  mdate timestamp NOT NULL,
  expiredate datetime default NULL,
  length int(11) default NULL,
  server varchar(50) default NULL,
  etag varchar(25) default NULL,
  nheadings int(11) default NULL,
  nlinks int(11) default NULL,
  headings mediumtext,
  ip mediumblob,
  PRIMARY KEY  (recordid)
) ENGINE=MyISAM AVG_ROW_LENGTH = 20000 MAX_ROWS = 10000000 DEFAULT CHARACTER SET=utf8;
</PRE>

<P>
<PRE>
CREATE TABLE html (
  recordid int(11) NOT NULL default '0',
  html mediumblob,
  PRIMARY KEY  (recordid)
) ENGINE=MyISAM AVG_ROW_LENGTH = 20000 MAX_ROWS = 10000000 DEFAULT CHARACTER SET=utf8;
</PRE>

<P>
<PRE>
CREATE TABLE links (
  recordid int(11) NOT NULL default '0',
  mynetlocid int(11) default NULL,
  urlid int(11) default NULL,
  netlocid int(11) default NULL,
  anchor text,
  linktype varchar(50) default NULL,
  KEY recordid (recordid),
  KEY urlid (urlid),
  KEY mynetlocid (mynetlocid),
  KEY netlocid (netlocid)
) ENGINE=MyISAM MAX_ROWS = 1000000000 DEFAULT CHARACTER SET=utf8;
</PRE>

<P>
<PRE>
CREATE TABLE meta (
  recordid int(11) NOT NULL default '0',
  name varchar(50) default NULL,
  value text,
  KEY recordid (recordid)
) ENGINE=MyISAM MAX_ROWS = 1000000000 DEFAULT CHARACTER SET=utf8;
</PRE>

<P>
<PRE>
CREATE TABLE analys (
  recordid int(11) NOT NULL default '0',
  name varchar(15) NOT NULL,
  value varchar(20),
  KEY recordid (recordid)
) ENGINE=MyISAM DEFAULT CHARACTER SET=utf8;
</PRE>

<P>
<PRE>
CREATE TABLE topic (
  recordid int(11) NOT NULL default '0',
  notation varchar(50) default NULL,
  abscore int(11) default NULL,
  relscore int(11) default NULL,
  terms text default NULL,
  algorithm varchar(25),
  KEY notation (notation),
  KEY recordid (recordid)
) ENGINE=MyISAM DEFAULT CHARACTER SET=utf8;
</PRE>

<P>

<H3><A NAME="SECTION05014400000000000000">
Administrative tables</A>
</H3>
<PRE>
CREATE TABLE netlocalias (
  netlocid int(11),
  netlocstr varchar(150) NOT NULL,
  KEY netlocid (netlocid),
  PRIMARY KEY netlocstr (netlocstr)
) ENGINE=MyISAM DEFAULT CHARACTER SET=utf8;
</PRE>

<P>
<PRE>
CREATE TABLE urlalias (
  urlid int(11),
  urlstr tinytext,
  KEY urlid (urlid),
  PRIMARY KEY urlstr (urlstr(255))
) ENGINE=MyISAM DEFAULT CHARACTER SET=utf8;
</PRE>

<P>
<code>topichierarchy have to initialized manually</code>
<BR><PRE>
CREATE TABLE topichierarchy (
  node int(11) NOT NULL DEFAULT '0',
  father int(11) DEFAULT NULL,
  notation varchar(50) NOT NULL DEFAULT '',
  caption varchar(255) DEFAULT NULL,
  level int(11) DEFAULT NULL,
  PRIMARY KEY node (node),
  KEY father (father),
  KEY notation (notation)
) ENGINE=MyISAM DEFAULT CHARACTER SET=utf8;
</PRE>

<P>
<PRE>
CREATE TABLE netlocs (
  netlocid int(11) NOT NULL auto_increment,
  netlocstr varchar(150) NOT NULL,
  retries int(11) NOT NULL DEFAULT 0,
  PRIMARY KEY (netlocstr),
  UNIQUE INDEX netlockid (netlocid)
) ENGINE=MyISAM DEFAULT CHARACTER SET=utf8;
</PRE>

<P>
<PRE>
CREATE TABLE urls (
  netlocid int(11) NOT NULL DEFAULT '0',
  urlid int(11) NOT NULL auto_increment,
  urlstr tinytext,
  path tinytext,
  PRIMARY KEY urlstr (urlstr(255)),
  INDEX netlocid (netlocid),
  UNIQUE INDEX urlid (urlid)
) ENGINE=MyISAM MAX_ROWS = 1000000000 DEFAULT CHARACTER SET=utf8;
</PRE>

<P>
<PRE>
CREATE TABLE urldb (
  netlocid int(11) NOT NULL default '0',
  netloclock int(11) NOT NULL default '0',
  urlid int(11) NOT NULL default '0',
  urllock int(11) NOT NULL default '0',
  harvest tinyint(1) NOT NULL default '0',
  retries int(11) NOT NULL default '0',
  PRIMARY KEY  (urlid),
  KEY netlocid (netlocid),
  KEY harvest (harvest)
) ENGINE=MyISAM DEFAULT CHARACTER SET=utf8;
</PRE>

<P>
<PRE>
CREATE TABLE newlinks (
  urlid int(11) NOT NULL,
  netlocid int(11) NOT NULL,
  PRIMARY KEY  (urlid)
) ENGINE=MyISAM DEFAULT CHARACTER SET=utf8;
</PRE>

<P>
<PRE>
CREATE TABLE recordurl (
  recordid int(11) NOT NULL auto_increment,
  urlid int(11) NOT NULL default '0',
  lastchecked timestamp NOT NULL,
  md5 char(32),
  fingerprint char(50),
  KEY md5 (md5),
  KEY fingerprint (fingerprint),
  PRIMARY KEY (urlid),
  KEY recordid (recordid)
) ENGINE=MyISAM DEFAULT CHARACTER SET=utf8;
</PRE>

<P>
<PRE>
CREATE TABLE admin (
  status enum('closed','open','paused','stopped') default NULL,
  schedulealgorithm enum('default','bigdefault','advanced') default 'default',
  queid int(11) NOT NULL default '0'
) ENGINE=MEMORY DEFAULT CHARACTER SET=utf8;
</PRE>

<P>
<code>Initialise admin to 'open' status</code>
<BR><code>INSERT INTO admin VALUES ('open','default',0)</code>
<BR><PRE>
CREATE TABLE log (
  pid int(11) NOT NULL default '0',
  id varchar(50) default NULL,
  date timestamp NOT NULL,
  message varchar(255) default NULL
) ENGINE=MyISAM DEFAULT CHARACTER SET=utf8;
</PRE>

<P>
<PRE>
CREATE TABLE que (
  netlocid int(11) NOT NULL default '0',
  urlid int(11) NOT NULL default '0',
  queid int(11) NOT NULL auto_increment,
  PRIMARY KEY  (queid)
) ENGINE=MEMORY DEFAULT CHARACTER SET=utf8;
</PRE>

<P>
<PRE>
CREATE TABLE robotrules (
  netlocid int(11) NOT NULL default '0',
  expire int(11) NOT NULL default '0',
  rule varchar(255) default '',
  KEY netlocid (netlocid)
) ENGINE=MyISAM DEFAULT CHARACTER SET=utf8;
</PRE>

<P>
<PRE>
CREATE TABLE oai (
  recordid int(11) NOT NULL default '0',
  md5 char(32),
  date timestamp,
  status enum('created', 'updated', 'deleted'),
  PRIMARY KEY (md5),
  KEY date (date)
) ENGINE=MyISAM DEFAULT CHARACTER SET=utf8;
</PRE>

<P>
<PRE>
CREATE TABLE exports (
  host varchar(30),
  port int,
  last timestamp DEFAULT '1999-12-31'
) ENGINE=MyISAM DEFAULT CHARACTER SET=utf8;
</PRE>

<P>

<H3><A NAME="SECTION05014500000000000000">
Create user dbuser with required priviligies</A>
</H3>
<PRE>
GRANT SELECT,INSERT,UPDATE,DELETE,CREATE,CREATE TEMPORARY TABLES,
   ALTER,LOCK TABLES ON $database.* TO $dbuser;
</PRE>

<P>
<PRE>
GRANT SELECT,INSERT,UPDATE,DELETE,CREATE,CREATE TEMPORARY TABLES,
   ALTER,LOCK TABLES ON $database.* TO $dbuser\@localhost;
</PRE>

<P>

<H2><A NAME="SECTION05015000000000000000"></A>
<A NAME="manpages"></A>
<BR>
Manual pages
</H2>

<H3><A NAME="SECTION05015100000000000000">
combineCtrl</A>
</H3>

<H4><A NAME="SECTION05015110000000000000"></A><A NAME="NAME"></A><A NAME="2411"></A>
<BR>
NAME
</H4>

<P>
combineCtrl - controls a Combine crawling job

<P>

<H4><A NAME="SECTION05015120000000000000"></A><A NAME="SYNOPSIS"></A><A NAME="2413"></A>
<BR>
SYNOPSIS
</H4>

<P>
combineCtrl  <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>action<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN> -jobname <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>name<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN>

<P>
where action can be one of start, kill, load, recyclelinks, reharvest, stat,
howmany, records, hosts, initMemoryTables, open, stop, pause, continue

<P>

<H4><A NAME="SECTION05015130000000000000"></A><A NAME="OPTIONS_AND_ARGUMENTS"></A><A NAME="2415"></A>
<BR>
OPTIONS AND ARGUMENTS
</H4>

<P>
jobname is used to find the appropriate configuration (mandatory)

<P>

<H5><A NAME="SECTION05015131000000000000"></A><A NAME="Actions_starting_killing_crawlers"></A><A NAME="2417"></A>
<BR>
Actions starting/killing crawlers
</H5>
<DL>
<DT><STRONG>start</STRONG></DT>
<DD>

<P>
takes an optional switch <TT>-harvesters n</TT> where <TT>n</TT> is the number of
crawler processes to start

<P>
</DD>
<DT><STRONG>kill</STRONG></DT>
<DD>

<P>
kills all active crawlers (and their associated combineRun monitors) for jobname

<P>
</DD>
</DL>
<H5><A NAME="SECTION05015132000000000000"></A><A NAME="Actions_loading_or_recycling_URLs_for_crawling"></A><A NAME="2427"></A>
<BR>
Actions loading or recycling URLs for crawling
</H5>
<DL>
<DT><STRONG>load</STRONG></DT>
<DD>

<P>
Read a list of URLs from STDIN (one per line) and schedules them for crawling

<P>
</DD>
<DT><STRONG>recyclelinks</STRONG></DT>
<DD>

<P>
Schedule all newly found (since last invocation of recyclelinks) 
links in crawled pages for crawling

<P>
</DD>
<DT><STRONG>reharvest</STRONG></DT>
<DD>

<P>
Schedules all pages in the database for crawling again (in order to check if
they have changed)

<P>
</DD>
</DL>
<H5><A NAME="SECTION05015133000000000000"></A><A NAME="Actions_for_controlling_scheduling_of_URLs"></A><A NAME="2437"></A>
<BR>
Actions for controlling scheduling of URLs
</H5>
<DL>
<DT><STRONG>open</STRONG></DT>
<DD>

<P>
opens database for URL scheduling (maybe after a stop)

<P>
</DD>
<DT><STRONG>stop</STRONG></DT>
<DD>

<P>
stops URL scheduling

<P>
</DD>
<DT><STRONG>pause</STRONG></DT>
<DD>

<P>
pauses URL scheduling

<P>
</DD>
<DT><STRONG>continue</STRONG></DT>
<DD>

<P>
continues  URL scheduling after a pause

<P>
</DD>
</DL>
<H5><A NAME="SECTION05015134000000000000"></A><A NAME="Misc_actions"></A><A NAME="2449"></A>
<BR>
Misc actions
</H5>
<DL>
<DT><STRONG>stat</STRONG></DT>
<DD>

<P>
prints out rudimentary status of the ready queue (ie eligible now) of URLs to be crawled

<P>
</DD>
<DT><STRONG>howmany</STRONG></DT>
<DD>

<P>
prints out rudimentary status of all URLs to be crawled

<P>
</DD>
<DT><STRONG>records</STRONG></DT>
<DD>

<P>
prints out the number of ercords in the SQL database

<P>
</DD>
<DT><STRONG>hosts</STRONG></DT>
<DD>

<P>
prints out rudimentary status of all hosts that have URLs to be crawled

<P>
</DD>
<DT><STRONG>initMemoryTables</STRONG></DT>
<DD>

<P>
initializes the administrative MySQL tables that are kept in memory

<P>
</DD>
</DL>
<H4><A NAME="SECTION05015140000000000000"></A><A NAME="DESCRIPTION"></A><A NAME="2463"></A>
<BR>
DESCRIPTION
</H4>

<P>
Implements various control functionality to administer a crawling job,
like starting and stoping crawlers, injecting URLs into the crawl queue,
scheduling newly found links for crawling, controlling scheduling, etc.

<P>
This is the preferred way of controling a crawl job.

<P>

<H4><A NAME="SECTION05015150000000000000"></A><A NAME="EXAMPLES"></A><A NAME="2465"></A>
<BR>
EXAMPLES
</H4>
<DL>
<DT><STRONG><TT>echo 'http://www.yourdomain.com/' <SPAN CLASS="MATH"><IMG
 WIDTH="9" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img25.png"
 ALT="$\vert$"></SPAN> combineCtrl load -jobname aatest</TT></STRONG></DT>
<DD>

<P>
Seed the crawling job <TT>aatest</TT> with a URL

<P>
</DD>
<DT><STRONG><TT>combineCtrl start -jobname aatest -harvesters 3</TT></STRONG></DT>
<DD>

<P>
Start 3 crawling processes for job <TT>aatest</TT>

<P>
</DD>
<DT><STRONG><TT>combineCtrl recyclelinks -jobname aatest</TT></STRONG></DT>
<DD>

<P>
Schedule all new links crawling

<P>
</DD>
<DT><STRONG><TT>combineCtrl stat -jobname aatest</TT></STRONG></DT>
<DD>

<P>
See how many URLs that are eligible for crawling right now.

<P>
</DD>
</DL>
<H4><A NAME="SECTION05015160000000000000"></A><A NAME="SEE_ALSO"></A><A NAME="2479"></A>
<BR>
SEE ALSO
</H4>

<P>
combine

<P>
Combine configuration documentation in <SPAN  CLASS="textit">/usr/share/doc/combine/</SPAN>.

<P>

<H4><A NAME="SECTION05015170000000000000"></A><A NAME="AUTHOR"></A><A NAME="2482"></A>
<BR>
AUTHOR
</H4>

<P>
Anders Ard&#246;, <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>anders.ardo@it.lth.se<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN>

<P>

<H4><A NAME="SECTION05015180000000000000"></A><A NAME="COPYRIGHT_AND_LICENSE"></A><A NAME="2484"></A>
<BR>
COPYRIGHT AND LICENSE
</H4>

<P>
Copyright (C) 2005 Anders Ard&#246;

<P>
This library is free software; you can redistribute it and/or modify
it under the same terms as Perl itself, either Perl version 5.8.4 or,
at your option, any later version of Perl 5 you may have available.

<P>
See the file LICENCE included in the distribution at
 <SPAN  CLASS="textsf">http://combine.it.lth.se/</SPAN>

<H3><A NAME="SECTION05015200000000000000">
combine</A>
</H3>

<H4><A NAME="SECTION05015210000000000000"></A><A NAME="NAME"></A><A NAME="2636"></A>
<BR>
NAME
</H4>

<P>
combine - main crawling machine in the  Combine system

<P>

<H4><A NAME="SECTION05015220000000000000"></A><A NAME="SYNOPSIS"></A><A NAME="2638"></A>
<BR>
SYNOPSIS
</H4>

<P>
combine -jobname <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>name<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN> -logname <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>id<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN>

<P>

<H4><A NAME="SECTION05015230000000000000"></A><A NAME="OPTIONS_AND_ARGUMENTS"></A><A NAME="2640"></A>
<BR>
OPTIONS AND ARGUMENTS
</H4>

<P>
jobname is used to find the appropriate configuration (mandatory)

<P>
logname is used as identifier in the log (in MySQL table log)

<P>

<H4><A NAME="SECTION05015240000000000000"></A><A NAME="DESCRIPTION"></A><A NAME="2642"></A>
<BR>
DESCRIPTION
</H4>

<P>
Does crawling, parsing, optional topic-check and stores in MySQL
database Normally started with the <TT>combineCtrl</TT> command. Briefly it
get's an URL from the MySQL database, which acts as a common
coordinator for a Combine job. The Web-page is fetched, provided it
passes the robot exclusion protocoll. The HTML ic cleaned using
<TT>Tidy</TT> and parsed into metadata, headings, text, links and link
achors. Then it is stored (optionaly provided a topic-check is passed
to keep the crawler focused) in the MySQL database in a structured
form.

<P>
A simple workflow for a trivial crawl job might look like:

<P>
<PRE>
    Initialize database and configuration
  combineINIT --jobname aatest
    Enter some seed URLs from a file with a list of URLs
  combineCtrl  load --jobname aatest &lt; seedURLs.txt
    Start 2 crawl processes
  combineCtrl  start --jobname aatest --harvesters 2
</PRE>
<PRE>
    For some time occasionally schedule new links for crawling
  combineCtrl recyclelinks --jobname aatest
    or look at the size of the ready queue
  combineCtrl stat --jobname aatest
</PRE>
<PRE>
    When satisfied kill the crawlers
  combineCtrl kill --jobname aatest
    Export data records in a highly structured XML format
  combineExport --jobname aatest
</PRE>

<P>
For more complex jobs you have to edit the job configuration file.

<P>

<H4><A NAME="SECTION05015250000000000000"></A><A NAME="SEE_ALSO"></A><A NAME="2652"></A>
<BR>
SEE ALSO
</H4>

<P>
combineINIT, combineCtrl

<P>
Combine configuration documentation in <SPAN  CLASS="textit">/usr/share/doc/combine/</SPAN>.

<P>

<H4><A NAME="SECTION05015260000000000000"></A><A NAME="AUTHOR"></A><A NAME="2655"></A>
<BR>
AUTHOR
</H4>

<P>
Anders Ard&#246;, <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>anders.ardo@it.lth.se<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN>

<P>

<H4><A NAME="SECTION05015270000000000000"></A><A NAME="COPYRIGHT_AND_LICENSE"></A><A NAME="2657"></A>
<BR>
COPYRIGHT AND LICENSE
</H4>

<P>
Copyright (C) 2005 Anders Ard&#246;

<P>
This library is free software; you can redistribute it and/or modify
it under the same terms as Perl itself, either Perl version 5.8.4 or,
at your option, any later version of Perl 5 you may have available.

<P>
See the file LICENCE included in the distribution at
 <SPAN  CLASS="textsf">http://combine.it.lth.se/</SPAN>

<H3><A NAME="SECTION05015300000000000000">
combineExport</A>
</H3>

<H4><A NAME="SECTION05015310000000000000"></A><A NAME="NAME"></A><A NAME="2720"></A>
<BR>
NAME
</H4>

<P>
combineExport - export records in XML from Combine database

<P>

<H4><A NAME="SECTION05015320000000000000"></A><A NAME="SYNOPSIS"></A><A NAME="2722"></A>
<BR>
SYNOPSIS
</H4>

<P>
combineExport -jobname <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>name<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN> [-profile alvis<SPAN CLASS="MATH"><IMG
 WIDTH="9" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img25.png"
 ALT="$\vert$"></SPAN>dc<SPAN CLASS="MATH"><IMG
 WIDTH="9" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img25.png"
 ALT="$\vert$"></SPAN>combine -charset utf8<SPAN CLASS="MATH"><IMG
 WIDTH="9" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img25.png"
 ALT="$\vert$"></SPAN>isolatin -number <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>n<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN> -recordid <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>n<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN> -md5 <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>MD5<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN> -pipehost <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>server<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN> -pipeport <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>n<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN> -incremental ]

<P>

<H4><A NAME="SECTION05015330000000000000"></A><A NAME="OPTIONS_AND_ARGUMENTS"></A><A NAME="2724"></A>
<BR>
OPTIONS AND ARGUMENTS
</H4>

<P>
jobname is used to find the appropriate configuration (mandatory)

<P>
<DL>
<DT><STRONG>-profile</STRONG></DT>
<DD>

<P>
Three profiles: alvis, dc, and combine . alvis and combine are similar XML formats.

<P>
'alvis' profile format is defined by the Alvis enriched document format DTD.
It uses charset UTF-8 per default.

<P>
'combine' is more compact with less redundancy.

<P>
'dc' is XML encoded Dublin Core data.

<P>
</DD>
<DT><STRONG>-charset</STRONG></DT>
<DD>

<P>
Selects a specific characterset from UTF-8, iso-latin-1
Overrides -profile settings.

<P>
</DD>
<DT><STRONG>-pipehost, -pipeport</STRONG></DT>
<DD>

<P>
Specifies the server-name and port to connect to and export data using the Alvis Pipeline.
Exports incrementally, ie all changes since last call to combineExport with the same pipehost
and pipeport.

<P>
</DD>
<DT><STRONG>-number</STRONG></DT>
<DD>

<P>
the max number of records to be exported

<P>
</DD>
<DT><STRONG>-recordid</STRONG></DT>
<DD>

<P>
Export just the one record with this recordid

<P>
</DD>
<DT><STRONG>-md5</STRONG></DT>
<DD>

<P>
Export just the one record with this MD5 checksum

<P>
</DD>
<DT><STRONG>-incremental</STRONG></DT>
<DD>

<P>
Exports incrementally, ie all changes since last call to combineExport using -incremental

<P>
</DD>
<DT><STRONG>-xsltscript</STRONG></DT>
<DD>

<P>
Generates records in Combine native format and converts them using this XSLT script
before output. See example scripts in /etc/combine/*.xsl

<P>
</DD>
</DL>
<H4><A NAME="SECTION05015340000000000000"></A><A NAME="DESCRIPTION"></A><A NAME="2744"></A>
<BR>
DESCRIPTION
</H4>

<H4><A NAME="SECTION05015350000000000000"></A><A NAME="EXAMPLES"></A><A NAME="2746"></A>
<BR>
EXAMPLES
</H4>
<PRE>
 Export all records in Alvis XML-format to the file recs.xml
   combineExport --jobname atest &gt; recs.xml
</PRE>
<PRE>
 Export 10 records to STDOUT
   combineExport --jobname atest --number 10
</PRE>
<PRE>
 Export all records in UTF-8 using Combine native format
   combineExport --jobname atest --profile combine --charset utf8 &gt; Zebrarecs.xml
</PRE>
<PRE>
 Incremental export of all changes from last call using localhost at port 6234 using the
 default profile (Alvis)
   combineExport --jobname atest --pipehost localhost --pipeport 6234
</PRE>
<H4><A NAME="SECTION05015360000000000000"></A><A NAME="SEE_ALSO"></A><A NAME="2756"></A>
<BR>
SEE ALSO
</H4>

<P>
Combine configuration documentation in <SPAN  CLASS="textit">/usr/share/doc/combine/</SPAN>.

<P>
Alvis XML schema (-profile alvis) at
<SPAN  CLASS="textsf">http://project.alvis.info/alvis_docs/enriched-document.xsd</SPAN>

<P>

<H4><A NAME="SECTION05015370000000000000"></A><A NAME="AUTHOR"></A><A NAME="2760"></A>
<BR>
AUTHOR
</H4>

<P>
Anders Ard&#246;, <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>anders.ardo@it.lth.se<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN>

<P>

<H4><A NAME="SECTION05015380000000000000"></A><A NAME="COPYRIGHT_AND_LICENSE"></A><A NAME="2762"></A>
<BR>
COPYRIGHT AND LICENSE
</H4>

<P>
Copyright (C) 2005 - 2006 Anders Ard&#246;

<P>
This library is free software; you can redistribute it and/or modify
it under the same terms as Perl itself, either Perl version 5.8.4 or,
at your option, any later version of Perl 5 you may have available.

<P>
<PRE>
 See the file LICENCE included in the distribution at
 L&lt;http://combine.it.lth.se/&gt;
</PRE>

<H3><A NAME="SECTION05015400000000000000">
combineRank</A>
</H3>

<H4><A NAME="SECTION05015410000000000000"></A><A NAME="NAME"></A><A NAME="2877"></A>
<BR>
NAME
</H4>

<P>
combineRank - calculates various Ranks for a Combine crawled database

<P>

<H4><A NAME="SECTION05015420000000000000"></A><A NAME="SYNOPSIS"></A><A NAME="2879"></A>
<BR>
SYNOPSIS
</H4>

<P>
combineRank  <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>action<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN> -jobname <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>name<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN> -verbose

<P>
where action can be one of PageRank, PageRankBL, NetLocRank, and
exportLinkGraph. Results on STDOUT.

<P>

<H4><A NAME="SECTION05015430000000000000"></A><A NAME="OPTIONS_AND_ARGUMENTS"></A><A NAME="2881"></A>
<BR>
OPTIONS AND ARGUMENTS
</H4>

<P>
jobname is used to find the appropriate configuration (mandatory)

<P>
verbose enables printing of ranks to STDOUT as SQL INSERT statements

<P>

<H5><A NAME="SECTION05015431000000000000"></A><A NAME="Actions_calculating_variants_of_PageRank"></A><A NAME="2883"></A>
<BR>
Actions calculating variants of PageRank
</H5>
<DL>
<DT><STRONG>PageRank</STRONG></DT>
<DD>

<P>
calculate standard PageRank

<P>
</DD>
<DT><STRONG>PageRankBL</STRONG></DT>
<DD>

<P>
calculate PageRanks with backlinks added for each link

<P>
</DD>
<DT><STRONG>NetLocRank</STRONG></DT>
<DD>

<P>
calculate SiteRank for each site and a local DocRank for documents within each site.
Global ranks are then calulated as SiteRank * DocRank

<P>
</DD>
</DL>
<H5><A NAME="SECTION05015432000000000000"></A><A NAME="Actions_exporting_link_data"></A><A NAME="2893"></A>
<BR>
Actions exporting link data
</H5>
<DL>
<DT><STRONG>exportLinkGraph</STRONG></DT>
<DD>

<P>
export linkgraph from Combine database

<P>
</DD>
</DL>
<H4><A NAME="SECTION05015440000000000000"></A><A NAME="DESCRIPTION"></A><A NAME="2899"></A>
<BR>
DESCRIPTION
</H4>

<P>
Implements calculation of different variants of PageRank.

<P>
Results are written to STDOUT and can be huge for large databases.

<P>
Linkgraph is exported in ASCII as a sparse matrix, one row per line.
First integer is the ID (urlid) of a page with links. The rest of
integers on the line are IDs for pages linked to. Ie
121 5624 23416 51423 267178
means that page 121 links to pages 5624 23416 51423 267178

<P>

<H4><A NAME="SECTION05015450000000000000"></A><A NAME="EXAMPLES"></A><A NAME="2901"></A>
<BR>
EXAMPLES
</H4>
<DL>
<DT><STRONG><TT>combineRank -jobname aatest -verbose PageRankBL</TT></STRONG></DT>
<DD>

<P>
calculate PageRank with backlinks, result on STDOUT

<P>
</DD>
<DT><STRONG><TT>combineRank -jobname aatest -verbose exportLinkGraph</TT></STRONG></DT>
<DD>

<P>
export the linkgraph to STDOUT

<P>
</DD>
</DL>
<H4><A NAME="SECTION05015460000000000000"></A><A NAME="SEE_ALSO"></A><A NAME="2909"></A>
<BR>
SEE ALSO
</H4>

<P>
combine

<P>
Combine configuration documentation in <SPAN  CLASS="textit">/usr/share/doc/combine/</SPAN>.

<P>

<H4><A NAME="SECTION05015470000000000000"></A><A NAME="AUTHOR"></A><A NAME="2912"></A>
<BR>
AUTHOR
</H4>

<P>
Anders Ard&#246;, <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>anders.ardo@it.lth.se<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN>

<P>

<H4><A NAME="SECTION05015480000000000000"></A><A NAME="COPYRIGHT_AND_LICENSE"></A><A NAME="2914"></A>
<BR>
COPYRIGHT AND LICENSE
</H4>

<P>
Copyright (C) 2006 Anders Ard&#246;

<P>
This library is free software; you can redistribute it and/or modify
it under the same terms as Perl itself, either Perl version 5.8.4 or,
at your option, any later version of Perl 5 you may have available.

<P>
See the file LICENCE included in the distribution at
 <SPAN  CLASS="textsf">http://combine.it.lth.se/</SPAN>

<H3><A NAME="SECTION05015500000000000000">
combineRun</A>
</H3>

<H4><A NAME="SECTION05015510000000000000"></A><A NAME="NAME"></A><A NAME="3012"></A>
<BR>
NAME
</H4>

<P>
combineRun - starts, monitors and restarts a combine harvesting process

<P>

<H4><A NAME="SECTION05015520000000000000"></A><A NAME="SYNOPSIS"></A><A NAME="3014"></A>
<BR>
SYNOPSIS
</H4>

<P>
combineRun <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>pidfile<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN> <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>combine command to run<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN>

<P>

<H4><A NAME="SECTION05015530000000000000"></A><A NAME="DESCRIPTION"></A><A NAME="3016"></A>
<BR>
DESCRIPTION
</H4>

<P>
Starts a program and monitors it in order to make sure there is alsways
a copy running. If the program dies it will be restarted with the same
parameters. Used by <TT>combineCtrl</TT> when starting combine crawling.

<P>

<H4><A NAME="SECTION05015540000000000000"></A><A NAME="SEE_ALSO"></A><A NAME="3019"></A>
<BR>
SEE ALSO
</H4>

<P>
combineCtrl

<P>

<H4><A NAME="SECTION05015550000000000000"></A><A NAME="AUTHOR"></A><A NAME="3021"></A>
<BR>
AUTHOR
</H4>

<P>
Anders Ard&#246;, <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>anders.ardo@it.lth.se<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN>

<P>

<H4><A NAME="SECTION05015560000000000000"></A><A NAME="COPYRIGHT_AND_LICENSE"></A><A NAME="3023"></A>
<BR>
COPYRIGHT AND LICENSE
</H4>

<P>
Copyright (C) 2005 Anders Ard&#246;

<P>
This library is free software; you can redistribute it and/or modify
it under the same terms as Perl itself, either Perl version 5.8.4 or,
at your option, any later version of Perl 5 you may have available.

<P>
See the file LICENCE included in the distribution at
 <SPAN  CLASS="textsf">http://combine.it.lth.se/</SPAN>

<H3><A NAME="SECTION05015600000000000000">
combineUtil</A>
</H3>

<H4><A NAME="SECTION05015610000000000000"></A><A NAME="NAME"></A><A NAME="3071"></A>
<BR>
NAME
</H4>

<P>
combineUtil - various operations on the Combine database

<P>

<H4><A NAME="SECTION05015620000000000000"></A><A NAME="SYNOPSIS"></A><A NAME="3073"></A>
<BR>
SYNOPSIS
</H4>

<P>
combineUtil  <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>action<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN> -jobname <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>name<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN>

<P>
where action can be one of stats, termstat, classtat,
 sanity, all, serveralias, resetOAI, restoreSanity,
 deleteNetLoc, deletePath, deleteMD5, deleteRecordid,
 addAlias

<P>

<H4><A NAME="SECTION05015630000000000000"></A><A NAME="OPTIONS_AND_ARGUMENTS"></A><A NAME="3075"></A>
<BR>
OPTIONS AND ARGUMENTS
</H4>

<P>
jobname is used to find the appropriate configuration (mandatory)

<P>

<H5><A NAME="SECTION05015631000000000000"></A><A NAME="Actions_listing_statistics"></A><A NAME="3077"></A>
<BR>
Actions listing statistics
</H5>
<DL>
<DT><STRONG>stats</STRONG></DT>
<DD>

<P>
Global statistics about the database

<P>
</DD>
<DT><STRONG>termstat</STRONG></DT>
<DD>

<P>
generates statistics about the terms from topic ontology matched in documents
(can be long output)

<P>
</DD>
<DT><STRONG>classtat</STRONG></DT>
<DD>

<P>
generates statistics about the topic classes assigned to documents

<P>
</DD>
</DL>
<H5><A NAME="SECTION05015632000000000000"></A><A NAME="Actions_for_sanity_controlls"></A><A NAME="3087"></A>
<BR>
Actions for sanity controlls
</H5>
<DL>
<DT><STRONG>sanity</STRONG></DT>
<DD>

<P>
Performs various sanity checks on the database

<P>
</DD>
<DT><STRONG>restoreSanity</STRONG></DT>
<DD>

<P>
Deletes records which sanity checks finds insane

<P>
</DD>
<DT><STRONG>resetOAI</STRONG></DT>
<DD>

<P>
Removes all history (ie 'deleted' records) from the OAI
table. This is done by removing the OAI table and
recreating it from the existing database.

<P>
</DD>
</DL>
<H5><A NAME="SECTION05015633000000000000"></A><A NAME="Action_all"></A><A NAME="3097"></A>
<BR>
Action all
</H5>

<P>
Does the actions: stats, sanity, classtat, termstat

<P>

<H5><A NAME="SECTION05015634000000000000"></A><A NAME="Actions_for_deleting_records"></A><A NAME="3099"></A>
<BR>
Actions for deleting records
</H5>
<DL>
<DT><STRONG>deleteNetLoc</STRONG></DT>
<DD>

<P>
Deletes all records matching the ','-separated list of server net-locations
(server-names optionally with port) in the switch -netlocstr.
Net-locations can include SQL wild cards ('%').

<P>
</DD>
<DT><STRONG>deletePath</STRONG></DT>
<DD>

<P>
Deletes all records matching the ','-separated list of URl
paths (excluding net-locations) in the switch -pathsubstr. Paths can include SQL wild cards ('%').

<P>
</DD>
<DT><STRONG>deleteMD5</STRONG></DT>
<DD>

<P>
Delete the record which has the MD5 in switch -md5

<P>
</DD>
<DT><STRONG>deleteRecordid</STRONG></DT>
<DD>

<P>
Delete the record which has the recordid in switch -recordid

<P>
</DD>
</DL>
<H5><A NAME="SECTION05015635000000000000"></A><A NAME="Actions_for_handling_server_aliases"></A><A NAME="3111"></A>
<BR>
Actions for handling server aliases
</H5>
<DL>
<DT><STRONG>serverAlias</STRONG></DT>
<DD>

<P>
Detect server aliases in the current database and do
a 'addAlias' on each detected alias.

<P>
</DD>
<DT><STRONG>addAlias</STRONG></DT>
<DD>

<P>
Manually add a serveralias to the system. Requires switches
-aliases and -preferred

<P>
</DD>
</DL>
<H4><A NAME="SECTION05015640000000000000"></A><A NAME="DESCRIPTION"></A><A NAME="3119"></A>
<BR>
DESCRIPTION
</H4>

<P>
Does various statistics generation as well as performing sanity checks on the database

<P>

<H4><A NAME="SECTION05015650000000000000"></A><A NAME="EXAMPLES"></A><A NAME="3121"></A>
<BR>
EXAMPLES
</H4>
<DL>
<DT><STRONG><TT>combineUtil termstat -jobname aatest</TT></STRONG></DT>
<DD>

<P>
Generate matched term statistics

<P>
</DD>
</DL>
<H4><A NAME="SECTION05015660000000000000"></A><A NAME="SEE_ALSO"></A><A NAME="3127"></A>
<BR>
SEE ALSO
</H4>

<P>
combine

<P>
Combine configuration documentation in <SPAN  CLASS="textit">/usr/share/doc/combine/</SPAN>.

<P>

<H4><A NAME="SECTION05015670000000000000"></A><A NAME="AUTHOR"></A><A NAME="3130"></A>
<BR>
AUTHOR
</H4>

<P>
Anders Ard&#246;, <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>anders.ardo@it.lth.se<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN>

<P>

<H4><A NAME="SECTION05015680000000000000"></A><A NAME="COPYRIGHT_AND_LICENSE"></A><A NAME="3132"></A>
<BR>
COPYRIGHT AND LICENSE
</H4>

<P>
Copyright (C) 2005 Anders Ard&#246;

<P>
This library is free software; you can redistribute it and/or modify
it under the same terms as Perl itself, either Perl version 5.8.4 or,
at your option, any later version of Perl 5 you may have available.

<P>
See the file LICENCE included in the distribution at
 <SPAN  CLASS="textsf">http://combine.it.lth.se/</SPAN>

<H3><A NAME="SECTION05015700000000000000">
Combine::FromHTML</A>
</H3>

<H4><A NAME="SECTION05015710000000000000"></A><A NAME="NAME"></A><A NAME="3262"></A>
<BR>
NAME
</H4>

<P>
Combine::FromHTML.pm - HTML parser in combine package

<P>

<H4><A NAME="SECTION05015720000000000000"></A><A NAME="AUTHOR"></A><A NAME="3264"></A>
<BR>
AUTHOR
</H4>

<P>
Yong Cao <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>tsao@munin.ub2.lu.se<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN> v0.06 1997-03-19
 Anders Ard&#248; 1998-07-18 
   added <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>AREA ... HREF=link ...<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN>
   fixed <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>A ... HREF=link ...<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN> regexp to be more general
 Anders Ard&#246; 2002-09-20
   added 'a' as a tag not to be replaced with space
   added removal of Cntrl-chars and some punctuation marks from IP
   added <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>style<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN>...<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>/style<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN> as something to be removed before processing
   beefed up compression of sequences of blanks to include <SPAN CLASS="MATH"><IMG
 WIDTH="13" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img5.png"
 ALT="$\backslash$"></SPAN>240 (non-breakable space)
   changed 'remove head' before text extraction to handle multiline matching (which can be
      introduced by decoding html entities)
   added compress blanks and remove CRs to metadata-content
 Anders Ard&#246; 2004-04
   Changed extraction process dramatically

<H3><A NAME="SECTION05015800000000000000">
Combine::FromTeX</A>
</H3>

<H4><A NAME="SECTION05015810000000000000"></A><A NAME="NAME"></A><A NAME="3297"></A>
<BR>
NAME
</H4>

<P>
Combine::FromTeX.pm - TeX parser in combine package

<P>

<H4><A NAME="SECTION05015820000000000000"></A><A NAME="AUTHOR"></A><A NAME="3299"></A>
<BR>
AUTHOR
</H4>
<PRE>
 Anders Ard 2000-06-11
</PRE>

<H3><A NAME="SECTION05015900000000000000">
Combine::HTMLExtractor</A>
</H3>

<H4><A NAME="SECTION05015910000000000000"></A><A NAME="NAME"></A><A NAME="3310"></A>
<BR>
NAME
</H4>

<P>
HTMLExtractor

<P>

<H4><A NAME="SECTION05015920000000000000"></A><A NAME="DESCRIPTION"></A><A NAME="3312"></A>
<BR>
DESCRIPTION
</H4>

<P>
Adopted from HTML::LinkExtractor - Extract links from an HTML document
by D.H (PodMaster)

<P>

<H4><A NAME="SECTION05015930000000000000"></A><A NAME="AUTHOR_Anders_Ardo"></A><A NAME="3314"></A>
<BR>
AUTHOR
Anders Ardo
</H4>

<P>
D.H (PodMaster)

<P>

<H4><A NAME="SECTION05015940000000000000"></A><A NAME="LICENSE"></A><A NAME="3316"></A>
<BR>
LICENSE
</H4>

<P>
Copyright (c) 2003 by D.H. (PodMaster).
All rights reserved.

<P>
This module is free software;
you can redistribute it and/or modify it under
the same terms as Perl itself.
The LICENSE file contains the full text of the license.

<H3><A NAME="SECTION050151000000000000000">
Combine::LoadTermList</A>
</H3>

<H4><A NAME="SECTION050151010000000000000"></A><A NAME="NAME"></A><A NAME="3339"></A>
<BR>
NAME
</H4>

<P>
LoadTermList

<P>

<H4><A NAME="SECTION050151020000000000000"></A><A NAME="DESCRIPTION"></A><A NAME="3341"></A>
<BR>
DESCRIPTION
</H4>

<P>
This a module in the DESIRE automatic classification system. Copyright 1999.

<P>
LoadTermList - A class for loading and storing 
      a stoplist with single words
      a termlist with classifications and weights

<P>
<PRE>
 Subroutines:
   LoadStopWordList(StopWordListFileName)
      loads a list of stopwords, one per line, from 
      the file StopWordListFileName.
</PRE>
<PRE>
   EraseStopWordList
      clears the stopword list
</PRE>
<PRE>
 Subroutines:
  LoadTermList(TermListFileName) - loads TermClass from file
  LoadTermListStemmed(TermListFileName) - same plus stems terms
</PRE>
<PRE>
 Input: A formatted term-list including weights and classifications
  Format:  &lt;weight&gt;: &lt;term_reg_exp&gt;=[&lt;classification&gt;, ]+
  weight can be a positive or negative number
  term_reg_exp can be words, phrases, boolean expressions (with @and
     as operator) on term_reg_exp or Perl regular expressions
</PRE>
<H4><A NAME="SECTION050151030000000000000"></A><A NAME="AUTHOR"></A><A NAME="3351"></A>
<BR>
AUTHOR
</H4>

<P>
Anders Ard&#246; <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>Anders.Ardo@it.lth.se<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN>

<P>

<H4><A NAME="SECTION050151040000000000000"></A><A NAME="COPYRIGHT_AND_LICENSE"></A><A NAME="3353"></A>
<BR>
COPYRIGHT AND LICENSE
</H4>

<P>
Copyright (C) 2005,2006 Anders Ard&#246;

<P>
This library is free software; you can redistribute it and/or modify
it under the same terms as Perl itself, either Perl version 5.8.4 or,
at your option, any later version of Perl 5 you may have available.

<P>
See the file LICENCE included in the distribution at
 <SPAN  CLASS="textsf">http://combine.it.lth.se/</SPAN>

<H3><A NAME="SECTION050151100000000000000">
Combine::Matcher</A>
</H3>

<H4><A NAME="SECTION050151110000000000000"></A><A NAME="NAME"></A><A NAME="3385"></A>
<BR>
NAME
</H4>

<P>
Matcher

<P>

<H4><A NAME="SECTION050151120000000000000"></A><A NAME="DESCRIPTION"></A><A NAME="3387"></A>
<BR>
DESCRIPTION
</H4>

<P>
This a module in the DESIRE automatic classification system. Copyright 1999.
Modified in the ALVIS project. Copyright 2004

<P>
Exported routines:
1. Fetching text:
   These routines all extract texts from a document (either
   a Combine XWI datastructure or a WWW-page identified by a URL.
   They all return: $meta, $head, $text, $url, $title, $size
        $meta: Metadata from document
        $head: Important text from document
        $text: Plain text from document
        $url: URL of the document
        $title: HTML title of the document
        $size: The size of the document

<P>
<PRE>
   Common input parameters:
        $DoStem: 1=do stemming; 0=no stemming
        $stoplist: object pointer to a LoadTermList object with a stoplist loaded
        $simple: 1=do simple loading; 0=advanced loading (might induce errors)
</PRE>
<PRE>
 getTextXWI
     parameters: $xwi, $DoStem, $stoplist, $simple
       $xwi is a Combine XWI datastructure
</PRE>
<PRE>
 getTextURL
    parameters: $url, $DoStem, $stoplist, $simple
       $url is the URL for the page to extract text from
</PRE>

<P>
2. Term matcher
    accepts a text as a (reference) parameter, matches each term in Term against text
    Matches are recorded in an associative array with class as key and summed weight as value.
  Match
    parameters: $text, $termlist
       $text: text to match against the termlist
       $termlist: object pointer to a LoadTermList object with a termlist loaded
    output: 
       %score: an associative array with classifications as keys and scores as values

<P>

<H4><A NAME="SECTION050151130000000000000"></A><A NAME="AUTHOR"></A><A NAME="3395"></A>
<BR>
AUTHOR
</H4>

<P>
Anders Ard&#246; <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>anders.ardo@it.lth.se<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN>

<P>

<H4><A NAME="SECTION050151140000000000000"></A><A NAME="COPYRIGHT_AND_LICENSE"></A><A NAME="3397"></A>
<BR>
COPYRIGHT AND LICENSE
</H4>

<P>
Copyright (C) 2005,2006 Anders Ard&#246;

<P>
This library is free software; you can redistribute it and/or modify
it under the same terms as Perl itself, either Perl version 5.8.4 or,
at your option, any later version of Perl 5 you may have available.

<P>
See the file LICENCE included in the distribution at
 <SPAN  CLASS="textsf">http://combine.it.lth.se/</SPAN>

<H3><A NAME="SECTION050151200000000000000">
Combine::PosMatcher</A>
</H3>

<H4><A NAME="SECTION050151210000000000000"></A><A NAME="NAME"></A><A NAME="3433"></A>
<BR>
NAME
</H4>

<P>
PosMatcher

<P>

<H4><A NAME="SECTION050151220000000000000"></A><A NAME="DESCRIPTION"></A><A NAME="3435"></A>
<BR>
DESCRIPTION
</H4>

<P>
This a module in the DESIRE automatic classification system. Copyright 1999.

<P>
Exported routines:
1. Fetching text:
   These routines all extract texts from a document (either a Combine record,
   a Combine XWI datastructure or a WWW-page identified by a URL.
   They all return: $meta, $head, $text, $url, $title, $size
        $meta: Metadata from document
        $head: Important text from document
        $text: Plain text from document
        $url: URL of the document
        $title: HTML title of the document
        $size: The size of the document

<P>
<PRE>
   Common input parameters:
        $DoStem: 1=do stemming; 0=no stemming
        $stoplist: object pointer to a LoadTermList object with a stoplist loaded
        $simple: 1=do simple loading; 0=advanced loading (might induce errors)
</PRE>
<PRE>
 getTextXWI
     parameters: $xwi, $DoStem, $stoplist, $simple
       $xwi is a Combine XWI datastructure
</PRE>
<PRE>
 getTextURL
    parameters: $url, $DoStem, $stoplist, $simple
       $url is the URL for the page to extract text from
</PRE>

<P>
2. Term matcher
    accepts a text as a (reference) parameter, matches each term in Term against text
    Matches are recorded in an associative array with class as key and summed weight as value.
  Match
    parameters: $text, $termlist
       $text: text to match against the termlist
       $termlist: object pointer to a LoadTermList object with a termlist loaded
    output: 
       %score: an associative array with classifications as keys and scores as values

<P>
3. Heuristics: sum scores down the classification tree to the leafs
  cleanEiTree
    parameters: %res - an associative array from Match
    output:     %res - same array

<P>

<H4><A NAME="SECTION050151230000000000000"></A><A NAME="AUTHOR"></A><A NAME="3443"></A>
<BR>
AUTHOR
</H4>

<P>
Anders Ard&#246;, <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>anders.ardo@it.lth.se<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN>

<P>

<H4><A NAME="SECTION050151240000000000000"></A><A NAME="COPYRIGHT_AND_LICENSE"></A><A NAME="3445"></A>
<BR>
COPYRIGHT AND LICENSE
</H4>

<P>
Copyright (C) 2005,2006 Anders Ard&#246;

<P>
This library is free software; you can redistribute it and/or modify
it under the same terms as Perl itself, either Perl version 5.8.4 or,
at your option, any later version of Perl 5 you may have available.

<P>
See the file LICENCE included in the distribution at
 <SPAN  CLASS="textsf">http://combine.it.lth.se/</SPAN>

<H3><A NAME="SECTION050151300000000000000">
Combine::RobotRules</A>
</H3>

<H4><A NAME="SECTION050151310000000000000"></A><A NAME="NAME"></A><A NAME="3483"></A>
<BR>
NAME
</H4>

<P>
RobotRules.pm

<P>

<H4><A NAME="SECTION050151320000000000000"></A><A NAME="AUTHOR"></A><A NAME="3485"></A>
<BR>
AUTHOR
</H4>

<P>
Anders Ardo version 1.0 2004-02-19

<H3><A NAME="SECTION050151400000000000000">
Combine::SD_SQL</A>
</H3>

<H4><A NAME="SECTION050151410000000000000"></A><A NAME="NAME"></A><A NAME="3496"></A>
<BR>
NAME
</H4>

<P>
SD_SQL

<P>

<H4><A NAME="SECTION050151420000000000000"></A><A NAME="DESCRIPTION"></A><A NAME="3498"></A>
<BR>
DESCRIPTION
</H4>

<P>
Reimplementation of sd.pl SD.pm and SDQ.pm using MySQL
 contains both recyc and guard

<P>
Basic idea is to have a table (urldb) that contains most URLs ever
inserted into the system together with a lock (the guard function) and
a boolean harvest-flag. Also in this table is the host part together with
its lock. URLs are selected from this table based on urllock, netloclock and
harvest and inserted into a queue (table que). URLs from this queue
are then given out to harvesters. The queue is implemented as:
# The admin table can be used to generate sequence numbers like this: 
#mysql<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN> update admin set queid=LAST_INSERT_ID(queid+1);
# and used to extract the next URL from the queue
#mysql<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN> select host,url from que where queid=LAST_INSERT_ID();
#
When the queue is empty it is filled from table urldb. Several different
algorithms can be used to fill it (round-robin, most urls, longest time
since harvest, ...). Since the harvest-flag and guard-lock are not updated
until the actual harvest is done it is OK to delete the queue and
regenerate it anytime.

<P>
##########################
#Questions, ideas, TODOs, etc
#Split table urldb into 2 tables - one for urls and one for hosts???
#Less efficient when filling que; more efficient when updating netloclock
#Datastruktur TABLE hosts:
create table hosts(
 host varchar(50) not null default '',
 netloclock int not null,
 retries int not null default 0,
 ant int not null default 0,
 primary key (host),
 key (ant), 
 key (netloclock)
 );

<P>
#############
Handle to many retries?

<P>
<PRE>
    algorithm takes an url from the host that was accessed longest ago
    ($hostid,$url)=SELECT host,url,id FROM hosts,urls WHERE 
         hosts.hostlock &lt; UNIX_TIMESTAMP()
         hosts.host=urls.host AND 
         urls.urllock &lt; UNIX_TIMESTAMP() AND 
         urls.harvest=1 ORDER BY hostlock LIMIT 1;
</PRE>
<PRE>
    algorithm takes an url from the host with most URLs
    ($hostid,$url)=SELECT host,url,id FROM hosts,urls WHERE 
         hosts.hostlock &lt; UNIX_TIMESTAMP()
         hosts.host=urls.host AND 
         urls.urllock &lt; UNIX_TIMESTAMP() AND 
         urls.harvest=1 ORDER BY host.ant DESC LIMIT 1;
</PRE>
<PRE>
    algorithm takes an url from any available host
    ($hostid,$url)=SELECT host,url,id FROM hosts,urls WHERE 
         hosts.hostlock &lt; UNIX_TIMESTAMP()
         hosts.host=urls.host AND 
         urls.urllock &lt; UNIX_TIMESTAMP() AND 
         urls.harvest=1 LIMIT 1;
</PRE>
<H4><A NAME="SECTION050151430000000000000"></A><A NAME="AUTHOR"></A><A NAME="3506"></A>
<BR>
AUTHOR
</H4>

<P>
Anders Ard&#246; <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>anders.ardo@it.lth.se<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN>

<P>

<H4><A NAME="SECTION050151440000000000000"></A><A NAME="COPYRIGHT_AND_LICENSE"></A><A NAME="3508"></A>
<BR>
COPYRIGHT AND LICENSE
</H4>

<P>
Copyright (C) 2005,2006 Anders Ard&#246;

<P>
This library is free software; you can redistribute it and/or modify
it under the same terms as Perl itself, either Perl version 5.8.4 or,
at your option, any later version of Perl 5 you may have available.

<P>
See the file LICENCE included in the distribution at
 <SPAN  CLASS="textsf">http://combine.it.lth.se/</SPAN>

<H3><A NAME="SECTION050151500000000000000">
Combine::XWI</A>
</H3>

<H4><A NAME="SECTION050151510000000000000"></A><A NAME="NAME"></A><A NAME="3548"></A>
<BR>
NAME
</H4>

<P>
XWI.pm - class for internal representation of a document record

<P>

<H4><A NAME="SECTION050151520000000000000"></A><A NAME="SYNOPSIS"></A><A NAME="3550"></A>
<BR>
SYNOPSIS
</H4>
<PRE>
 use Combine::XWI;
 $xwi = new Combine::XWI;
</PRE>
<PRE>
 #single value record variables
 $xwi-&gt;server($server);
</PRE>
<PRE>
 my $server = $xwi-&gt;server();
</PRE>
<PRE>
 #original content
 $xwi-&gt;content(\$html);
</PRE>
<PRE>
 my $text = ${$xwi-&gt;content()};
</PRE>
<PRE>
 #multiple value record variables
 $xwi-&gt;meta_add($name1,$value1);
 $xwi-&gt;meta_add($name2,$value2);
</PRE>
<PRE>
 $xwi-&gt;meta_rewind;
 my ($name,$content);
 while (1) {
  ($name,$content) = $xwi-&gt;meta_get;
  last unless $name;
 }
</PRE>
<H4><A NAME="SECTION050151530000000000000"></A><A NAME="DESCRIPTION"></A><A NAME="3566"></A>
<BR>
DESCRIPTION
</H4>

<P>
Provides methods for storing and retrieving structured records
representing crawled documents.

<P>

<H4><A NAME="SECTION050151540000000000000"></A><A NAME="METHODS"></A><A NAME="3568"></A>
<BR>
METHODS
</H4>

<H5><A NAME="SECTION050151541000000000000"></A><A NAME="new_"></A><A NAME="3570"></A>
<BR>
new()
</H5>

<H5><A NAME="SECTION050151542000000000000"></A><A NAME="XXX_val_"></A><A NAME="3572"></A>
<BR>
XXX($val)
</H5>

<P>
Saves $val using AUTOLOAD. Can later be retrieved, eg

<P>
<PRE>
    $xwi-&gt;MyVar('My value');
    $t = $xwi-&gt;MyVar;
</PRE>

<P>
will set $t to 'My value'

<P>

<H5><A NAME="SECTION050151543000000000000"></A><A NAME="_reset_"></A><A NAME="3576"></A>
<BR>
*_reset()
</H5>

<P>
Forget all values.

<P>

<H5><A NAME="SECTION050151544000000000000"></A><A NAME="_rewind_"></A><A NAME="3578"></A>
<BR>
*_rewind()
</H5>

<P>
*_get will start with the first value.

<P>

<H5><A NAME="SECTION050151545000000000000"></A><A NAME="_add"></A><A NAME="3580"></A>
<BR>
*_add
</H5>

<P>
stores values into the datastructure

<P>

<H5><A NAME="SECTION050151546000000000000"></A><A NAME="_get"></A><A NAME="3582"></A>
<BR>
*_get
</H5>

<P>
retrieves values from the datastructure

<P>

<H5><A NAME="SECTION050151547000000000000"></A><A NAME="meta_reset_meta_rewind_meta_add_meta_get_"></A><A NAME="3584"></A>
<BR>
meta_reset() / meta_rewind() / meta_add() / meta_get()
</H5>

<P>
Stores the content of Meta-tags

<P>
Takes/Returns 2 parameters: Name, Content

<P>
<PRE>
 $xwi-&gt;meta_add($name1,$value1);
 $xwi-&gt;meta_add($name2,$value2);
</PRE>
<PRE>
 $xwi-&gt;meta_rewind;
 my ($name,$content);
 while (1) {
  ($name,$content) = $xwi-&gt;meta_get;
  last unless $name;
 }
</PRE>
<H5><A NAME="SECTION050151548000000000000"></A><A NAME="xmeta_reset_xmeta_rewind_xmeta_add_xmeta_get_"></A><A NAME="3590"></A>
<BR>
xmeta_reset() / xmeta_rewind() / xmeta_add() / xmeta_get()
</H5>

<P>
Extended information from Meta-tags. Not used.

<P>

<H5><A NAME="SECTION050151549000000000000"></A><A NAME="url_remove_url_reset_url_rewind_url_add_url_get_"></A><A NAME="3592"></A>
<BR>
url_remove() / url_reset() / url_rewind() / url_add() / url_get()
</H5>

<P>
Stores all URLs (ie if multiple URLs for the same page) for this record

<P>
Takes/Returns 1 parameter: URL

<P>

<H5><A NAME="SECTION0501515410000000000000"></A><A NAME="heading_reset_heading_rewind_heading_add_heading_get_"></A><A NAME="3594"></A>
<BR>
heading_reset() / heading_rewind() / heading_add() / heading_get()
</H5>

<P>
Stores headings from HTML documents

<P>
Takes/Returns 1 parameter: Heading text

<P>

<H5><A NAME="SECTION0501515411000000000000"></A><A NAME="link_reset_link_rewind_link_add_link_get_"></A><A NAME="3596"></A>
<BR>
link_reset() / link_rewind() / link_add() / link_get()
</H5>

<P>
Stores links from documents

<P>
Takes/Returns 5 parameters: URL, netlocid, urlid, Anchor text, Link type

<P>

<H5><A NAME="SECTION0501515412000000000000"></A><A NAME="robot_reset_robot_rewind_robot_add_robot_get_"></A><A NAME="3598"></A>
<BR>
robot_reset() / robot_rewind() / robot_add() / robot_get()
</H5>

<P>
Stores calculated information, like genre, language, etc

<P>
Takes/Returns 2 parameters Name, Value. Both are strings with max length Name: 15, Value: 20

<P>

<H5><A NAME="SECTION0501515413000000000000"></A><A NAME="topic_reset_topic_rewind_topic_add_topic_get_"></A><A NAME="3600"></A>
<BR>
topic_reset() / topic_rewind() / topic_add() / topic_get()
</H5>

<P>
Stores result of topic classification.

<P>
Takes/Returns 5 parameters: Class, Absolute score, Normalized score, Terms, Algorithm id

<P>
Class, Terms, and Algorithm id are strings with max
lengths Class: 50, and Algorithm id: 25

<P>
Absolute score, and Normalized score are integers

<P>
Normalized score and Terms are optional and may be replaced with 0, and '' respectively

<P>

<H4><A NAME="SECTION050151550000000000000"></A><A NAME="SEE_ALSO"></A><A NAME="3602"></A>
<BR>
SEE ALSO
</H4>

<P>
Combine focused crawler main site <SPAN  CLASS="textsf">http://combine.it.lth.se/</SPAN>

<P>

<H4><A NAME="SECTION050151560000000000000"></A><A NAME="AUTHOR"></A><A NAME="3605"></A>
<BR>
AUTHOR
</H4>

<P>
Yong Cao <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>tsao@munin.ub2.lu.se<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN> v0.05 1997-03-13

<P>
Anders Ard&#246;, <SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$&lt;$"></SPAN>anders.ardo@it.lth.se<SPAN CLASS="MATH"><IMG
 WIDTH="18" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$&gt;$"></SPAN>

<P>

<H4><A NAME="SECTION050151570000000000000"></A><A NAME="COPYRIGHT_AND_LICENSE"></A><A NAME="3607"></A>
<BR>
COPYRIGHT AND LICENSE
</H4>

<P>
Copyright (C) 2005,2006 Anders Ard&#246;

<P>
This library is free software; you can redistribute it and/or modify
it under the same terms as Perl itself, either Perl version 5.8.4 or,
at your option, any later version of Perl 5 you may have available.

<P>
See the file LICENCE included in the distribution at
 <SPAN  CLASS="textsf">http://combine.it.lth.se/</SPAN>

<H3><A NAME="SECTION050151600000000000000">
Combine::selurl</A>
</H3>

<H4><A NAME="SECTION050151610000000000000"></A><A NAME="NAME"></A><A NAME="3733"></A>
<BR>
NAME
</H4>

<P>
selurl - Normalise and validate URIs for harvesting

<P>

<H4><A NAME="SECTION050151620000000000000"></A><A NAME="INTRODUCTION"></A><A NAME="3735"></A>
<BR>
INTRODUCTION
</H4>

<P>
Selurl selects and normalises URIs on basis of both general practice
(hostname lowercasing, portnumber substsitution etc.) and
Combine-specific handling (aplpying config_allow, config_exclude,
config_serveralias and other relevant config settings).

<P>
The Config settings catered for currently are:

<P>
maxUrlLength - the maximum length of an unnormalised URL
allow - Perl regular to identify allowed URLs
exclude - Perl regular expressions to exclude URLs from harvesting
serveralias - Aliases of server names
sessionids - List sessionid markers to be removed

<P>
A selurl object can hold a single URL and has methods to obtain its
subparts as defined in URI.pm, plus some methods to normalise and
validate it in Combine context.

<P>

<H4><A NAME="SECTION050151630000000000000"></A><A NAME="BUGS"></A><A NAME="3737"></A>
<BR>
BUGS
</H4>

<P>
Currently, the only schemes supported are http, https and ftp. Others
may or may not work correctly. For one thing, we assume the scheme has
an internet hostname/port.

<P>
clone() will only return a copy of the real URI object, not a new
selurl.

<P>
URI URI-escapes the strings fed into it by new() once. Existing
percent signs in the input are left untouched, which implicates that:

<P>
(a) there is no risk of double-encoding; and

<P>
(b) if the original contained an inadvertent sequence that could
be interpreted as an escape sequence, uri_unescape will not
render the original input (e.g. url_with_%66_in_it goes whoop)
If you know that the original has not yet been escaped and wish to
safeguard potential percent signs, you'll have to escape them (and
only them) once before you offer it to new().

<P>
A problem with URI is, that its object is not a hash we can
piggyback our data on, so I had to resort to AUTOLOAD to emulate
inheritance. I find this ugly, but well, this *is* Perl, so what'd
you expect?

<P>

<DIV CLASS="navigation"><HR>
<!--Navigation Panel-->
<A NAME="tex2html736"
  HREF="node17.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next" SRC="next.png"></A> 
<A NAME="tex2html732"
  HREF="node15.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up" SRC="up.png"></A> 
<A NAME="tex2html728"
  HREF="node15.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous" SRC="prev.png"></A> 
<A NAME="tex2html734"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents" SRC="contents.png"></A>  
<BR>
<B> Next:</B> <A NAME="tex2html737"
  HREF="node17.html">About this document ...</A>
<B> Up:</B> <A NAME="tex2html733"
  HREF="node15.html">.</A>
<B> Previous:</B> <A NAME="tex2html729"
  HREF="node15.html">.</A>
 &nbsp; <B>  <A NAME="tex2html735"
  HREF="node1.html">Contents</A></B> </DIV>
<!--End of Navigation Panel-->
<ADDRESS>
root
2007-03-07
</ADDRESS>
</BODY>
</HTML>
